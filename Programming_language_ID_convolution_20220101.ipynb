{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "lS8T-dxnwfjO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toCWkHOHmad-",
        "outputId": "ad0a1387-5fe5-4148-bbc5-31eb1371c495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting NLTK\n",
            "  Downloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
            "Requirement already satisfied: click in c:\\users\\sipocz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from NLTK) (7.1.2)\n",
            "Requirement already satisfied: joblib in c:\\users\\sipocz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from NLTK) (0.17.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\sipocz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from NLTK) (4.52.0)\n",
            "Collecting regex>=2021.8.3\n",
            "  Downloading regex-2021.11.10-cp38-cp38-win_amd64.whl (273 kB)\n",
            "Installing collected packages: regex, NLTK\n",
            "Successfully installed NLTK-3.6.7 regex-2021.11.10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\n",
            "You should consider upgrading via the 'c:\\users\\sipocz\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\sipocz\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip install NLTK\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xFjap2PTfYbv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVKfMbXhg0ZO",
        "outputId": "e429245b-16aa-4748-9cfc-1f4d2818c4bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emoji in c:\\users\\sipocz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.6.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\n",
            "You should consider upgrading via the 'c:\\users\\sipocz\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "! pip install emoji\n",
        "import emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "UMHsrRn4f7Ct",
        "outputId": "93a926b6-54a9-4ad3-a74b-98d2787391ac"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8ca639ce6e73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0memoji\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdemojize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hello üëç\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/emoji/core.py\u001b[0m in \u001b[0;36mdemojize\u001b[0;34m(string, use_aliases, delimiters, language, version, handle_version)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdelimiters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdelimiters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_emoji_regexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'\\ufe0e'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'\\ufe0f'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/emoji/core.py\u001b[0m in \u001b[0;36mget_emoji_regexp\u001b[0;34m(language)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0memojis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0municode_codes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEMOJI_DATA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mu'('\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mu'|'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mescape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memojis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mu')'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0m_EMOJI_REGEXP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_EMOJI_REGEXP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/re.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;34m\"Compile a regular expression pattern, returning a Pattern object.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpurge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_DEBUG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/sre_compile.py\u001b[0m in \u001b[0;36m_code\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[0;31m# compile the pattern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m     \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSUCCESS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/sre_compile.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(code, pattern, flags)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;31m# _compile_info(code, p, _combine_flags(flags, add_flags, del_flags))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_combine_flags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_flags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdel_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMARK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/sre_compile.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(code, pattern, flags)\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0mskip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0;31m# _compile_info(code, av, flags)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                 \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m                 \u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJUMP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0mtailappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/sre_compile.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(code, pattern, flags)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0miscased\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascii_iscased\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtolower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascii_tolower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mav\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mLITERAL_CODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_IGNORECASE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/sre_parse.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__delitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSubPattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "emoji.demojize(\"hello üëç\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDQLvAy5gI0C"
      },
      "source": [
        "##Sz√≥szedet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tYKeq-BTB0B"
      },
      "outputs": [],
      "source": [
        "train_file_url=\"https://github.com/sipocz/Programming_language_classification/raw/e61a328b63d89bc7f3ca744fefcbf9b162fe52c5/orig/train.csv\"\n",
        "test_file_url=\"https://github.com/sipocz/Programming_language_classification/raw/e61a328b63d89bc7f3ca744fefcbf9b162fe52c5/orig/test.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDUZMjUkgIIe"
      },
      "outputs": [],
      "source": [
        "!rm *train*\n",
        "!rm *test*\n",
        "\n",
        "!wget $train_file_url\n",
        "!wget $test_file_url\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDtEcJB5haQF"
      },
      "outputs": [],
      "source": [
        "df_test=pd.read_csv(\"test.csv\")\n",
        "df_test.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dA8Mk878pUdU"
      },
      "outputs": [],
      "source": [
        "df_train=pd.read_csv(\"train.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OczaGqbTqKgz"
      },
      "outputs": [],
      "source": [
        "df_train.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKWduEZGJdY0"
      },
      "outputs": [],
      "source": [
        "languages=set(df_train.language)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fc82uz3ZJm-h"
      },
      "outputs": [],
      "source": [
        "len(languages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vGSDdwGqneG"
      },
      "outputs": [],
      "source": [
        "test=list(df_test.code)\n",
        "train=list(df_train.code)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDMqa72say6c"
      },
      "outputs": [],
      "source": [
        "def decorate_list(inpstr:str):\n",
        "    aa=inpstr.split()\n",
        "    i=0\n",
        "    print(\"'''\")\n",
        "    for a in aa:\n",
        "        print(a, end=\" \")\n",
        "        i+=1\n",
        "        if i % 10==0:\n",
        "            print(\"\", end=\"\\n\")\n",
        "    print(\"\\n'''\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuRrm2HJja_6"
      },
      "outputs": [],
      "source": [
        "alltext=train+test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMkENkO1Xkne"
      },
      "outputs": [],
      "source": [
        "keywords_swift='''\n",
        "Class deinit Enum extension Func import Init operator private protocol \n",
        "public static struct subscript break case continue default do else \n",
        "for return switch where while as false is dynamicType super \n",
        "true _COLUMN_ Let in _FILE_ internal typealias if nil var \n",
        "self unowned _FUNCTION_ _LINE_ associativity convenience dynamic didSet precedence final \n",
        "get infix inout right set type lazy left mutating none \n",
        "weak willSet prefix nonmutating optional override postfix Protocol required \n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWGSxmLtbOlQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LI1t7EVcWV3A"
      },
      "outputs": [],
      "source": [
        "keywords_ruby='''\n",
        "BEGIN END alias and begin break case class def module \n",
        "next nil not or redo rescue retry return elsif end \n",
        "false ensure for if true undef unless do else super \n",
        "then until when while defined? self \n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OI3pUmeGV6ov"
      },
      "outputs": [],
      "source": [
        "keywords_php='''\n",
        "__halt_compiler abstract and array as break callable case catch class \n",
        "clone const continue declare default die do echo else elseif \n",
        "empty enddeclare endfor endforeach endif endswitch endwhile eval exit extends \n",
        "final finally fn for foreach function global goto if implements \n",
        "include include_once instanceof insteadof interface isset list match namespace new \n",
        "or print private protected public readonly require require_once return static \n",
        "switch throw trait try unset use var while xor yield \n",
        "yield from \n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DEv2KuY2WVHS"
      },
      "outputs": [],
      "source": [
        "keywords_scala='''\n",
        "abstract case catch class def do else extends false final \n",
        "finally for forSome if implicit import lazy macro match new \n",
        "null object override package private protected return sealed super this \n",
        "throw trait try true type val var while with yield \n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqGWl6d3VaZt"
      },
      "outputs": [],
      "source": [
        "keywords_julia='''\n",
        "@doc_str do macrocall struct __dot__ end memq toplevel _cmd eqv \n",
        "memv true _str false module try abstract finally mutable tuple \n",
        "bitstype for none type block function parameters typealias call global \n",
        "primitive typed_comprehension catch if quote typed_hcat cell1d kw ref typed_vcat \n",
        "comparison line return vect const local row where curly macro \n",
        "string \n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__VT1ufyPSad"
      },
      "outputs": [],
      "source": [
        "keywords_javascript='''\n",
        "abstract arguments boolean break byte case catch char class const \n",
        "continue debugger default delete do double else enum eval export \n",
        "extends false final finally float for function goto if implements \n",
        "import in instanceof int interface let long native new null \n",
        "package private protected public return short static super switch synchronized \n",
        "this throw throws transient true try typeof var void volatile \n",
        "while with yield Array Date eval function hasOwnProperty Infinity isFinite \n",
        "isNaN isPrototypeOf length Math NaN name Number Object prototype String \n",
        "toString undefined valueOf \n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QL5-xC5GOsAX"
      },
      "outputs": [],
      "source": [
        "keywords_java='''\n",
        "abstract assert boolean break byte case catch char class const \n",
        "continue default do double else enum extends final finally float \n",
        "for goto if implement imports instanceof int interface long native \n",
        "new package private protected public return short static strictfp super \n",
        "switch synchronized this throw throws transient try void volatile while \n",
        "false null true \n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAFF3fmWOL0U"
      },
      "outputs": [],
      "source": [
        "keywords_go='''\n",
        "break case chan const continue default defer else fallthrough for \n",
        "func go goto if import interface map package range return \n",
        "select struct switch type var \n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyFNWwDoNePm"
      },
      "outputs": [],
      "source": [
        "keywords_f_sharp='''\n",
        "atomic break checked component const constraint constructor continue eager fixed \n",
        "fori functor include method mixin object parallel params process protected \n",
        "pure sealed tailcall trait virtual volatile \n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUdQzbYLNFJd"
      },
      "outputs": [],
      "source": [
        "keywords_dart='''\n",
        "assert break case catch class const continue default do else \n",
        "enum extends false final finally for if in is new \n",
        "null rethrow return super switch this throw true try var \n",
        "void while with \n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OON-rBKGS9w"
      },
      "outputs": [],
      "source": [
        "keywords_c='''\n",
        "auto break case char const continue default do double else \n",
        "enum extern float for goto if int long register return \n",
        "short signed sizeof static struct switch typedef union unsigned void \n",
        "volatile while \n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVXVR5wwHAIs"
      },
      "outputs": [],
      "source": [
        "keywords_python='''\n",
        "False await else import pass None break except in raise \n",
        "True class finally is return and continue for lambda try \n",
        "as def from nonlocal while assert del global not with \n",
        "async elif if or yield \n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdKJWV2_LZpq"
      },
      "outputs": [],
      "source": [
        "keywords_cpp='''\n",
        "alignas double reinterpret_cast alignof dynamic_cast requires and else return and_eq \n",
        "enum short asm explicit signed atomic_cancel export sizeof atomic_commit extern \n",
        "static atomic_noexcept false static_assert auto float static_cast bitand for struct \n",
        "bitor friend switch bool goto synchronized break if template case \n",
        "import this catch inline thread_local char int throw char16_t long \n",
        "true char32_t module try class mutable typedef compl namespace typeid \n",
        "concept new typename const noexcept union constexpr not unsigned const_cast \n",
        "not_eq using continue nullptr virtual co_await operator void co_return or \n",
        "volatile co_yield or_eq wchar_t decltype private while default protected xor \n",
        "delete public xor_eq do register \n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dGKnKE0Ie4V"
      },
      "outputs": [],
      "source": [
        "keywords_c_sharp='''\n",
        "abstract as base bool break byte case catch char checked \n",
        "class const continue decimal default delegate do double else enum \n",
        "event explicit extern false finally fixed float for foreach goto \n",
        "if implicit in int interface internal is lock long namespace \n",
        "new null object operator out override params private protected public \n",
        "readonly ref return sbyte sealed short sizeof stackalloc static string \n",
        "struct switch this throw true try typeof uint ulong unchecked \n",
        "unsafe ushort using virtual void volatile while \n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMWbhghVK1N4"
      },
      "outputs": [],
      "source": [
        "keywords_r='''\n",
        "if else repeat while function for in next break TRUE \n",
        "FALSE NULL Inf NaN NA NA_integer_ NA_real_ NA_complex_ NA_character_ ... \n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfnPWTaRj1C8"
      },
      "outputs": [],
      "source": [
        "def keyword_convert(keystr:str):\n",
        "    keywords_list=keystr.split()\n",
        "    out=[\"_\"+c+\"_\" for c in keywords_list]\n",
        "    return(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cD4peLFur1sN"
      },
      "outputs": [],
      "source": [
        "languages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrnF06rIGsL_"
      },
      "outputs": [],
      "source": [
        "list_of_pogramming_languages=(keywords_r,keywords_c,keywords_cpp,keywords_c_sharp,keywords_dart,\n",
        "                             keywords_f_sharp,keywords_go,keywords_java,keywords_javascript,\n",
        "                             keywords_julia,keywords_php,keywords_python,keywords_ruby,\n",
        "                             keywords_scala,keywords_swift\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS6yvr8vsMbc"
      },
      "outputs": [],
      "source": [
        "def create_keyword_set(prog_key_list:list):\n",
        "    output=[]\n",
        "    for keys in prog_key_list:\n",
        "        #print(keys)\n",
        "        setx=keyword_convert(keys)\n",
        "        output=output+setx\n",
        "        #print(output)\n",
        "    out=set(output)\n",
        "    outdict={o[1:-1]:o for o in out}\n",
        "    print(outdict)\n",
        "    return(outdict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvVsHYsywExd"
      },
      "outputs": [],
      "source": [
        "keyword_dict=create_keyword_set(list_of_pogramming_languages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXoSALSKwJ0d"
      },
      "outputs": [],
      "source": [
        "keyword_dict[\"checked\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9gx6vqhG1hL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5JF5V62JATC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCN90l7Ijkb5"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def remove_URL(text):\n",
        "    \"\"\"Remove URLs from a text string\"\"\"\n",
        "    return re.sub(r\"http\\S+\", \"\", text)\n",
        "\n",
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', string)\n",
        "\n",
        "def is_number(inp:str):\n",
        "    a=re.search(\"[\\d]\",inp)\n",
        "    if a==None: \n",
        "        return(False)\n",
        "    return(True)\n",
        "\n",
        "def strip_all_entities(text):\n",
        "    import emoji\n",
        "    import re,string\n",
        "    entity_prefixes = ['‚Äú','@','#',\"!\",\"?\"]\n",
        "    for separator in  string.punctuation:\n",
        "        if separator not in entity_prefixes :\n",
        "            text = text.replace(separator,' ')\n",
        "    words = []\n",
        "    for word in text.split():\n",
        "        word = word.strip()\n",
        "        if word:\n",
        "            if word[0] not in entity_prefixes:\n",
        "                words.append(word)\n",
        "    return ' '.join(words)\n",
        "\n",
        "def query_sentence(alltext:list,index:int):\n",
        "    print(f\"orig: {alltext[index]}\")\n",
        "    \n",
        "    inp=alltext[index]\n",
        "    inp=remove_URL(inp)\n",
        "    inp=emoji.demojize(inp)\n",
        "    txt=inp\n",
        "    #inp=strip_all_entities(inp)\n",
        "    txt=txt.replace(\"_\",\" _underline_ \")\n",
        "    txt=re.sub(\"[-+]?[0-9]*\\.?[0-9]+(e[-+]?[0-9]+)?\",\" _number_ \",txt) #numeric\n",
        "    txt=re.sub(\"[\\\"]?[\\w]*[\\\"]\",\" _string_ \",txt) #string\n",
        "    txt=re.sub(\"[\\']?[\\w]*[\\']\",\" _string_ \",txt) #string\n",
        "    \n",
        "\n",
        "\n",
        "    txt=txt.replace(\",\",\" _comma_ \").replace(\".\",\" _point_ \").replace(\"!\",\" _exclamation_ \").replace(\"#\",\" _hashmark_ \").replace(\"???\",\"?\").replace(\"??\",\"?\").replace(\"?\",\" _questionmark_ \")\n",
        "    txt=txt.replace(\"  \",\" \").replace(\"*\",\" _star_ \").replace('\"',\" _apostrofe_ \").replace(\"‚Äú\",\" _apostrofe_ \").replace(\"'\",\" _apostrofe_ \")\n",
        "    txt=txt.replace(\"=>\",\" _identical_ \").replace(\"=\",\" _equal_ \").replace(\"-\",\" _minus_ \").replace(\"^\",\" _powerup_ \")\n",
        "    txt=txt.replace(\"[\",\" _crotchets_open_ \").replace(\"]\",\" _crotchets_close_ \").replace(\"{\",\" _brace_open_ \").replace(\"}\",\" _brace_close_ \").replace(\"(\",\" _bracket_open_ \").replace(\")\",\" _bracket_close_ \")\n",
        "    txt=txt.replace(\"\\n\",\" _new_line_ \").replace(\"\\t\",\" _tab_ \").replace(\";\",\" _semicolon_ \").replace(\":\",\" _colon_ \").replace(\"&\",\" _AND_ \").replace(\"|\",\" _OR_ \").replace(\"\\\\\",\" _switch_char_ \")\n",
        "    txt=txt.replace(\"<\",\" _smaller_sign_ \").replace(\">\",\" _larger_sign_ \").replace(\"+\",\" _plus_ \").replace(\"$\",\" _dollar_ \").replace(\"/\",\" _division_ \")\n",
        "    txt=txt.replace(\"%\",\" _percentage_ \").replace(\"@\",\" _at_sign_ \")\n",
        "    txt=txt.replace(\"~\",\" _wiggle_ \")\n",
        "\n",
        "    \n",
        "    \n",
        "    #txt=txt.lower()\n",
        "    print(\"after replace=\",txt)\n",
        "    #print(txt)\n",
        "    normal=\"\"\n",
        "    #keyword dict usage\n",
        "    for i in txt.split(\" \"):\n",
        "        w1=i.strip()\n",
        "        if w1 in keyword_dict:\n",
        "            w1=keyword_dict[w1]\n",
        "            #print(w1)\n",
        "        #print(\"**\"+w1+\"**\")\n",
        "        if len (w1)!=0:\n",
        "            if w1[0]!=\"_\" and w1[-1]!=\"_\":\n",
        "                w1=\"_\"+w1.upper()+\"_\"\n",
        "        #print(\"--\"+w1+\"--\")\n",
        "        normal += w1+\" \"\n",
        "\n",
        "    print(f\"  conv: {normal}\")\n",
        "    return(normal)\n",
        "\n",
        "def convert_sentence(sent):\n",
        "    #print(f\"orig: {sent}\")\n",
        "    \n",
        "    inp=sent\n",
        "    inp=remove_URL(inp)\n",
        "    inp=emoji.demojize(inp)\n",
        "    txt=inp\n",
        "    #inp=strip_all_entities(inp)\n",
        "    txt=txt.replace(\"_\",\" _underline_ \")\n",
        "    txt=re.sub(\"[-+]?[0-9]*\\.?[0-9]+(e[-+]?[0-9]+)?\",\" _number_ \",txt) #numeric\n",
        "    txt=re.sub(\"[\\\"]?[\\w]*[\\\"]\",\" _string_ \",txt) #string\n",
        "    txt=re.sub(\"[\\']?[\\w]*[\\']\",\" _string_ \",txt) #string\n",
        "    \n",
        "\n",
        "\n",
        "    txt=txt.replace(\",\",\" _comma_ \").replace(\".\",\" _point_ \").replace(\"!\",\" _exclamation_ \").replace(\"#\",\" _hashmark_ \").replace(\"???\",\"?\").replace(\"??\",\"?\").replace(\"?\",\" _questionmark_ \")\n",
        "    txt=txt.replace(\"  \",\" \").replace(\"*\",\" _star_ \").replace('\"',\" _apostrofe_ \").replace(\"‚Äú\",\" _apostrofe_ \").replace(\"'\",\" _apostrofe_ \")\n",
        "    txt=txt.replace(\"=>\",\" _identical_ \").replace(\"=\",\" _equal_ \").replace(\"-\",\" _minus_ \").replace(\"^\",\" _powerup_ \")\n",
        "    txt=txt.replace(\"[\",\" _crotchets_open_ \").replace(\"]\",\" _crotchets_close_ \").replace(\"{\",\" _brace_open_ \").replace(\"}\",\" _brace_close_ \").replace(\"(\",\" _bracket_open_ \").replace(\")\",\" _bracket_close_ \")\n",
        "    txt=txt.replace(\"\\n\",\" _new_line_ \").replace(\"\\t\",\" _tab_ \").replace(\";\",\" _semicolon_ \").replace(\":\",\" _colon_ \").replace(\"&\",\" _AND_ \").replace(\"|\",\" _OR_ \").replace(\"\\\\\",\" _switch_char_ \")\n",
        "    txt=txt.replace(\"<\",\" _smaller_sign_ \").replace(\">\",\" _larger_sign_ \").replace(\"+\",\" _plus_ \").replace(\"$\",\" _dollar_ \").replace(\"/\",\" _division_ \")\n",
        "    txt=txt.replace(\"%\",\" _percentage_ \").replace(\"@\",\" _at_sign_ \")\n",
        "    txt=txt.replace(\"~\",\" _wiggle_ \")\n",
        "\n",
        "    \n",
        "    \n",
        "    #txt=txt.lower()\n",
        "    #print(\"after replace=\",txt)\n",
        "    #print(txt)\n",
        "    normal=\"\"\n",
        "    #keyword dict usage\n",
        "    for i in txt.split(\" \"):\n",
        "        w1=i.strip()\n",
        "        if w1 in keyword_dict:\n",
        "            w1=keyword_dict[w1]\n",
        "            #print(w1)\n",
        "        #print(\"**\"+w1+\"**\")\n",
        "        if len (w1)!=0:\n",
        "            if w1[0]!=\"_\" and w1[-1]!=\"_\":\n",
        "                w1=\"_\"+w1.upper()+\"_\"\n",
        "        #print(\"--\"+w1+\"--\")\n",
        "        normal += w1+\" \"\n",
        "\n",
        "    #print(f\"  conv: {normal}\")\n",
        "    return(normal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9tQrQt_HyG7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xahobt8Yq2_0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WExlmfSO80zf"
      },
      "outputs": [],
      "source": [
        "sent0=query_sentence(train,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BykaPpXlmoZ7"
      },
      "outputs": [],
      "source": [
        "\n",
        "token=nltk.word_tokenize(sent0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIS4f1UasN7C"
      },
      "outputs": [],
      "source": [
        "len(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcD3MQTzopbe"
      },
      "outputs": [],
      "source": [
        "def list_tokenizer(lin:list):\n",
        "    l1=[]\n",
        "    s1=set()\n",
        "    i=0\n",
        "    for list_element in lin:\n",
        "        i+=1\n",
        "        print(f\"{i}\",end=\".\")\n",
        "        \n",
        "        c1=convert_sentence(list_element)\n",
        "        token=nltk.word_tokenize(c1)\n",
        "        l1.append(token)\n",
        "        s_token=set(token)\n",
        "        s1=s1.union(s_token)\n",
        "    return(s1,l1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vROujcpunn9X"
      },
      "outputs": [],
      "source": [
        "s_train,l_train=list_tokenizer(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WIqawJ4t573"
      },
      "outputs": [],
      "source": [
        "len(s_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wvuABaSyO2P"
      },
      "outputs": [],
      "source": [
        "s_test,l_test=list_tokenizer(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPA9siC5yOxS"
      },
      "outputs": [],
      "source": [
        "s_all=s_train.union(s_test)\n",
        "l_all=l_train+l_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCzPApU-ymiO"
      },
      "outputs": [],
      "source": [
        "l_all_words=[]\n",
        "maxx=len(l_all)\n",
        "for i in range(len(l_all)):\n",
        "    print(f\"{i}/{maxx}%\")\n",
        "    l_all_words=l_all_words+l_all[i]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERFNhur-ymdV"
      },
      "outputs": [],
      "source": [
        "len(s_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZVKvT1a68Ey"
      },
      "outputs": [],
      "source": [
        "l_all_words[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFvf2FhU7GEM"
      },
      "outputs": [],
      "source": [
        "l_all_words.count(\"_equal_\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seIGb0558IIy"
      },
      "outputs": [],
      "source": [
        "l_all_words_mini=[]\n",
        "i=0\n",
        "for aword in list(s_all):\n",
        "    i+=1\n",
        "    if i%10==0:\n",
        "        print(f\"{i}\")\n",
        "    w_count=l_all_words.count(aword)\n",
        "    if w_count>1:\n",
        "        l_all_words_mini.append(aword)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTPyWUnxMrEk"
      },
      "outputs": [],
      "source": [
        "len(l_all_words_mini)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCOItXwxM4Je"
      },
      "outputs": [],
      "source": [
        "wordlist_df=pd.DataFrame()\n",
        "wordlist_df[\"Word_list\"]=l_all_words_mini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhDdypaGOOe3"
      },
      "outputs": [],
      "source": [
        "wordlist_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pkl0ek8lOalW"
      },
      "outputs": [],
      "source": [
        "wordlist_df.to_csv(\"wordlist.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJ5Qe0rdTACp"
      },
      "outputs": [],
      "source": [
        "\n",
        "def convert_sentence_lwordmini(sent):\n",
        "    #print(f\"orig: {sent}\")\n",
        "    \n",
        "    inp=sent\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "    #txt=txt.lower()\n",
        "    #print(\"after replace=\",txt)\n",
        "    #print(txt)\n",
        "    normal=\"\"\n",
        "    #keyword dict usage\n",
        "    for i in inp:\n",
        "        w1=i\n",
        "        if w1 in l_all_words_mini:\n",
        "            w1=w1\n",
        "        else:\n",
        "            w1=\"_ID_\"\n",
        "        #print(\"--\"+w1+\"--\")\n",
        "        normal += w1+\" \"\n",
        "\n",
        "    #print(f\"  conv: {normal}\")\n",
        "    return(normal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzMOTKbN2G3R"
      },
      "source": [
        "##Ment√©s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oG-lrw20Mxv6"
      },
      "outputs": [],
      "source": [
        "t_train=[]\n",
        "i=0\n",
        "for train_word in l_train:   #len(alltext)\n",
        "    i+=1\n",
        "    if i%10==0:\n",
        "        print(f\"{i}. {train_word}\") \n",
        "    print(f\"{i}\", end=\" \")\n",
        "    t_train.append(convert_sentence_lwordmini(train_word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Evqw82-wOI9S"
      },
      "outputs": [],
      "source": [
        "t_test=[]\n",
        "i=0\n",
        "for test_word in l_test:   #len(alltext)\n",
        "    i+=1\n",
        "    if i%10==0:\n",
        "        print(f\"{i}. {test_word}\") \n",
        "    print(f\"{i}\", end=\" \")\n",
        "    t_test.append(convert_sentence_lwordmini(test_word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9ZUtwPWj2wv"
      },
      "outputs": [],
      "source": [
        "t=t_train+t_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nVJioCXMxHG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zjwf-ZsDMphv"
      },
      "outputs": [],
      "source": [
        "t_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIoSRwse2GOY"
      },
      "outputs": [],
      "source": [
        "word_dict={v:i+1 for i,v in enumerate(s_all)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rphnkvcJgfD2"
      },
      "outputs": [],
      "source": [
        "len(word_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFTg1Nt8feV8"
      },
      "outputs": [],
      "source": [
        "word_dict[\"_STD_\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LDx7viC5QMrc"
      },
      "outputs": [],
      "source": [
        "df_train[\"Word_list\"]=t_train\n",
        "df_test[\"Word_list\"]=t_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Hx93h2XrzfL"
      },
      "outputs": [],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLY9Hzahiz_o"
      },
      "outputs": [],
      "source": [
        "def words_to_number(df2,word_dict,col=\"Review\"):\n",
        "    all_sent=[]\n",
        "    for sentence in df2[col]:\n",
        "        sent_list=sentence.strip().split()\n",
        "        out=[]\n",
        "        for word in sent_list:\n",
        "            #print(word)\n",
        "            if word in word_dict:\n",
        "                out.append(word_dict[word]) \n",
        "        all_sent.append(out)\n",
        "    return(all_sent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlqGS0RTua2Y"
      },
      "outputs": [],
      "source": [
        "df_test_sent=words_to_number(df_test,word_dict,col=\"Word_list\")\n",
        "df_test[\"Words_in_Numbers\"]=df_test_sent\n",
        "\n",
        "df_train_sent=words_to_number(df_train,word_dict,col=\"Word_list\")\n",
        "df_train[\"Words_in_Numbers\"]=df_train_sent\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bozt8qRZgC-l"
      },
      "outputs": [],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFiCC208ZgxJ"
      },
      "outputs": [],
      "source": [
        "df_test.to_csv(\"test_id_big.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iS3-t17yZy6Q"
      },
      "outputs": [],
      "source": [
        "df_train.to_csv(\"train_id_big.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBfIDKGjuyQc"
      },
      "outputs": [],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RCD1OKy7kJr"
      },
      "source": [
        "###---------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdZa4d2H7nO8"
      },
      "source": [
        "###Adatbet√∂lt√©s SZAVAK BET√ñLT√âSE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqnFYKaeCkda"
      },
      "source": [
        "### adatbet√∂lt√©s mondatok bet√∂lt√©se"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t8zcn0gafG-W"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsQObqfegZ7M",
        "outputId": "b654f415-2cc6-489d-eea5-0054a21e2ef2"
      },
      "outputs": [],
      "source": [
        "_OS_=\"windows\"\n",
        "\n",
        "if _OS_==\"linux\":\n",
        "\n",
        "    !rm *id*\n",
        "    train_converted=\"https://github.com/sipocz/Programming_language_classification/raw/767438414c2c76db7cfb13ee2ef3fd0dff2184c1/orig/train_id_big.zip\"\n",
        "    test_converted=\"https://github.com/sipocz/Programming_language_classification/raw/767438414c2c76db7cfb13ee2ef3fd0dff2184c1/orig/test_id_big.csv\"\n",
        "\n",
        "\n",
        "    !wget $train_converted\n",
        "    !unzip train_id_big.zip\n",
        "elif _OS_==\"windows\":\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LshFLrqKMVuR"
      },
      "outputs": [],
      "source": [
        "df_train=pd.read_csv(\"train_id_big.csv\")\n",
        "#df_test=pd.read_csv(\"test_200.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhsaFzgFquK1"
      },
      "source": [
        "### \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "x3HJcQ35MWAn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XomafEhUMWAp"
      },
      "source": [
        "### adatbet√∂lt√©s mondatok bet√∂lt√©se"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w60OcdVMWAp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqbe8kFxgJav"
      },
      "source": [
        "##Tanul√°s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "e-_C5UdDMpyH",
        "outputId": "7764fad5-fa5f-49d1-8d1c-a4b07e1541e1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>code</th>\n",
              "      <th>language</th>\n",
              "      <th>Word_list</th>\n",
              "      <th>Words_in_Numbers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>14026</td>\n",
              "      <td>var result = testObj1 | testObj2;\\...</td>\n",
              "      <td>c-sharp</td>\n",
              "      <td>_var_ _RESULT_ _equal_ _TESTOBJ_ _number_ _OR_...</td>\n",
              "      <td>[6880, 758, 7553, 14581, 13255, 11128, 14581, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>12201</td>\n",
              "      <td>///     Initializes a new instance of ...</td>\n",
              "      <td>c-sharp</td>\n",
              "      <td>_division_ _division_ _division_ _INITIALIZES_...</td>\n",
              "      <td>[17760, 17760, 17760, 2202, 2228, 2046, 6330, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>17074</td>\n",
              "      <td>/*\\n\\n     Explanation :- a user gives a Strin...</td>\n",
              "      <td>javascript</td>\n",
              "      <td>_division_ _star_ _new_line_ _new_line_ _EXPLA...</td>\n",
              "      <td>[17760, 13892, 10859, 10859, 3065, 18475, 1242...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>21102</td>\n",
              "      <td>int sum = 0;\\n\\n         for (int i = ...</td>\n",
              "      <td>c-plus-plus</td>\n",
              "      <td>_int_ _SUM_ _equal_ _number_ _semicolon_ _new_...</td>\n",
              "      <td>[12481, 12527, 7553, 13255, 11167, 10859, 1085...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>53065</td>\n",
              "      <td>if (p-&gt;data &lt; min)\\n\\n         {\\n\\n  ...</td>\n",
              "      <td>c</td>\n",
              "      <td>_if_ _bracket_open_ _P_ _minus_ _larger_sign_ ...</td>\n",
              "      <td>[10569, 15649, 11062, 12420, 12166, 1803, 1572...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>29901</td>\n",
              "      <td>&gt;&gt;&gt; insertion_sort([]) == sorted([])\\n\\n  ...</td>\n",
              "      <td>python</td>\n",
              "      <td>_larger_sign_ _larger_sign_ _larger_sign_ _INS...</td>\n",
              "      <td>[12166, 12166, 12166, 5627, 6315, 6980, 15649,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>32980</td>\n",
              "      <td>* @details The Trie data structure is impleme...</td>\n",
              "      <td>c-plus-plus</td>\n",
              "      <td>_star_ _at_sign_ _DETAILS_ _THE_ _TRIE_ _DATA_...</td>\n",
              "      <td>[13892, 16321, 15569, 13053, 10822, 1803, 5567...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>22010</td>\n",
              "      <td>*/\\n\\n static void test() {\\n\\n     data_stru...</td>\n",
              "      <td>c-plus-plus</td>\n",
              "      <td>_star_ _division_ _new_line_ _new_line_ _stati...</td>\n",
              "      <td>[13892, 17760, 10859, 10859, 1543, 6375, 5281,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>80574</td>\n",
              "      <td># =&gt; 2\\n\\n puts remove_elements([0, 1, 2, 2, 3...</td>\n",
              "      <td>ruby</td>\n",
              "      <td>_hashmark_ _identical_ _number_ _new_line_ _ne...</td>\n",
              "      <td>[17614, 3209, 13255, 10859, 10859, 9921, 16565...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>35990</td>\n",
              "      <td>// graph is represented as an array of edg...</td>\n",
              "      <td>c</td>\n",
              "      <td>_division_ _division_ _GRAPH_ _is_ _REPRESENTE...</td>\n",
              "      <td>[17760, 17760, 13552, 3455, 15324, 9752, 16851...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>11384</td>\n",
              "      <td>// Notice that the return type is automati...</td>\n",
              "      <td>c-plus-plus</td>\n",
              "      <td>_division_ _division_ _NOTICE_ _THAT_ _THE_ _r...</td>\n",
              "      <td>[17760, 17760, 7623, 5136, 13053, 2578, 12341,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>88732</td>\n",
              "      <td>{\\n\\n                     nrig...</td>\n",
              "      <td>c-sharp</td>\n",
              "      <td>_brace_open_ _new_line_ _new_line_ _NRIGHT_ _m...</td>\n",
              "      <td>[2769, 10859, 10859, 8845, 12420, 12420, 11167...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0     id                                               code  \\\n",
              "0            0  14026              var result = testObj1 | testObj2;\\...   \n",
              "1            1  12201          ///     Initializes a new instance of ...   \n",
              "2            2  17074  /*\\n\\n     Explanation :- a user gives a Strin...   \n",
              "3            3  21102          int sum = 0;\\n\\n         for (int i = ...   \n",
              "4            4  53065          if (p->data < min)\\n\\n         {\\n\\n  ...   \n",
              "5            5  29901      >>> insertion_sort([]) == sorted([])\\n\\n  ...   \n",
              "6            6  32980   * @details The Trie data structure is impleme...   \n",
              "7            7  22010   */\\n\\n static void test() {\\n\\n     data_stru...   \n",
              "8            8  80574  # => 2\\n\\n puts remove_elements([0, 1, 2, 2, 3...   \n",
              "9            9  35990      // graph is represented as an array of edg...   \n",
              "10          10  11384      // Notice that the return type is automati...   \n",
              "11          11  88732                  {\\n\\n                     nrig...   \n",
              "\n",
              "       language                                          Word_list  \\\n",
              "0       c-sharp  _var_ _RESULT_ _equal_ _TESTOBJ_ _number_ _OR_...   \n",
              "1       c-sharp  _division_ _division_ _division_ _INITIALIZES_...   \n",
              "2    javascript  _division_ _star_ _new_line_ _new_line_ _EXPLA...   \n",
              "3   c-plus-plus  _int_ _SUM_ _equal_ _number_ _semicolon_ _new_...   \n",
              "4             c  _if_ _bracket_open_ _P_ _minus_ _larger_sign_ ...   \n",
              "5        python  _larger_sign_ _larger_sign_ _larger_sign_ _INS...   \n",
              "6   c-plus-plus  _star_ _at_sign_ _DETAILS_ _THE_ _TRIE_ _DATA_...   \n",
              "7   c-plus-plus  _star_ _division_ _new_line_ _new_line_ _stati...   \n",
              "8          ruby  _hashmark_ _identical_ _number_ _new_line_ _ne...   \n",
              "9             c  _division_ _division_ _GRAPH_ _is_ _REPRESENTE...   \n",
              "10  c-plus-plus  _division_ _division_ _NOTICE_ _THAT_ _THE_ _r...   \n",
              "11      c-sharp  _brace_open_ _new_line_ _new_line_ _NRIGHT_ _m...   \n",
              "\n",
              "                                     Words_in_Numbers  \n",
              "0   [6880, 758, 7553, 14581, 13255, 11128, 14581, ...  \n",
              "1   [17760, 17760, 17760, 2202, 2228, 2046, 6330, ...  \n",
              "2   [17760, 13892, 10859, 10859, 3065, 18475, 1242...  \n",
              "3   [12481, 12527, 7553, 13255, 11167, 10859, 1085...  \n",
              "4   [10569, 15649, 11062, 12420, 12166, 1803, 1572...  \n",
              "5   [12166, 12166, 12166, 5627, 6315, 6980, 15649,...  \n",
              "6   [13892, 16321, 15569, 13053, 10822, 1803, 5567...  \n",
              "7   [13892, 17760, 10859, 10859, 1543, 6375, 5281,...  \n",
              "8   [17614, 3209, 13255, 10859, 10859, 9921, 16565...  \n",
              "9   [17760, 17760, 13552, 3455, 15324, 9752, 16851...  \n",
              "10  [17760, 17760, 7623, 5136, 13053, 2578, 12341,...  \n",
              "11  [2769, 10859, 10859, 8845, 12420, 12420, 11167...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.head(12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2eCsucwRtIt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wGBReaGM6-zn"
      },
      "outputs": [],
      "source": [
        "\n",
        "def ylabel_convert_5(sentiment):\n",
        "    ytrain=[]\n",
        "\n",
        "    for sent in sentiment:\n",
        "        #print(sent)\n",
        "        sent=sent[0]\n",
        "        if sent.lower()==\"r\":\n",
        "            o=[1,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "        elif sent.lower()==\"c\":\n",
        "            o=[0,1,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "        elif sent.lower()==\"c-plus-plus\":\n",
        "            o=[0,0,1,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "        elif sent.lower()==\"c-sharp\":\n",
        "            o=[0,0,0,1,0,0,0,0,0,0,0,0,0,0,0]\n",
        "        elif sent.lower()==\"dart\":\n",
        "            o=[0,0,0,0,1,0,0,0,0,0,0,0,0,0,0]\n",
        "        elif sent.lower()==\"f-sharp\":\n",
        "            o=[0,0,0,0,0,1,0,0,0,0,0,0,0,0,0]\n",
        "        elif sent.lower()==\"go\":\n",
        "            o=[0,0,0,0,0,0,1,0,0,0,0,0,0,0,0]\n",
        "        elif sent.lower()==\"java\":\n",
        "            o=[0,0,0,0,0,0,0,1,0,0,0,0,0,0,0]\n",
        "        elif sent.lower()==\"javascript\":\n",
        "            o=[0,0,0,0,0,0,0,0,1,0,0,0,0,0,0]\n",
        "        elif sent.lower()==\"julia\":\n",
        "            o=[0,0,0,0,0,0,0,0,0,1,0,0,0,0,0]          \n",
        "        elif sent.lower()==\"php\":\n",
        "            o=[0,0,0,0,0,0,0,0,0,0,1,0,0,0,0]\n",
        "        elif sent.lower()==\"python\":\n",
        "            o=[0,0,0,0,0,0,0,0,0,0,0,1,0,0,0]\n",
        "        elif sent.lower()==\"ruby\":\n",
        "            o=[0,0,0,0,0,0,0,0,0,0,0,0,1,0,0]\n",
        "        elif sent.lower()==\"scala\":\n",
        "            o=[0,0,0,0,0,0,0,0,0,0,0,0,0,1,0]\n",
        "        elif sent.lower()==\"swift\":\n",
        "            o=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,1]          \n",
        "\n",
        "        ytrain.append(o)\n",
        "    return(ytrain)\n",
        "\n",
        "\n",
        "\n",
        "def ylabel_convert_1(sentiment):\n",
        "    ytrain=[]\n",
        "    for sent in sentiment:\n",
        "        if sent==\"negative\":\n",
        "            o=[1,0]\n",
        "        if sent==\"neutral\":\n",
        "            o=[0.5,0.5]\n",
        "        if sent==\"positive\":\n",
        "            o=[0,1]\n",
        "        ytrain.append(o)\n",
        "    return(ytrain)\n",
        "\n",
        "def ylabel_convert_3(sentiment):\n",
        "    ytrain=[]\n",
        "    for sent in sentiment:\n",
        "        if sent.lower()==\"kitaifa\":\n",
        "            o=[1,0,0,0,0]\n",
        "        elif sent.lower()==\"michezo\":\n",
        "            o=[0,1,0,0,0]\n",
        "        elif sent.lower()==\"biashara\":\n",
        "            o=[0,0,1,0,0]\n",
        "        elif sent.lower()==\"kamataifa\":\n",
        "            o=[0,0,0,1,0]\n",
        "        elif sent.lower()==\"burudani\":\n",
        "            o=[0,0,0,0,1]\n",
        "               \n",
        "              \n",
        "        ytrain.append(o)\n",
        "    return(ytrain)\n",
        "\n",
        "\n",
        "\n",
        "def ylabel_convert_4(senti):\n",
        "    ytrain=[]\n",
        "    oo=list(senti.values)\n",
        "    ytrain=[list(i) for i in oo]\n",
        "    return ytrain      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIxgkOKjTv8M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4QGQRyHcwtC6"
      },
      "outputs": [],
      "source": [
        "sentiment=[\"language\" ]  # \n",
        "\n",
        "ytrain=ylabel_convert_5(df_train[sentiment].values)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6KZN3Ex5UXSW"
      },
      "outputs": [],
      "source": [
        "#ytrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5LXoUuB_tZDc"
      },
      "outputs": [],
      "source": [
        "def str_2_numlist(strin):\n",
        "    x=strin[1:-1]\n",
        "    x=x.split(\",\")\n",
        "    try:\n",
        "        o=[float(i) for i in x]\n",
        "    except:\n",
        "        print(x)\n",
        "    return(o)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2UjgMZztoPH",
        "outputId": "0858b176-c20b-47f0-df1a-b066128c9cb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[123.0, 23.0, 433.0, 5423.0, 123.0, 12312.0, 123.0, 35432.0]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "str_2_numlist(\"[123,23, 433,5423, 123, 12312, 123 ,35432]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "3cq0dEopjXs2",
        "outputId": "c220f3d6-68b8-4243-e6c6-533101aa98cb"
      },
      "outputs": [],
      "source": [
        "#word_dict[\"_ID_\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aQJ4h5LbFXbK"
      },
      "outputs": [],
      "source": [
        "def id_eliminator(l:list,id:float=6083):\n",
        "    o=[]\n",
        "    idnum=0\n",
        "    for i in l:\n",
        "        if i !=id:\n",
        "            o.append(i)\n",
        "            idnum=0\n",
        "        if i==id and idnum==0:\n",
        "            o.append(i)\n",
        "            idnum+=1\n",
        "    return(o)\n",
        "\n",
        "        \n",
        "\n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TNi-g2CNARwY"
      },
      "outputs": [],
      "source": [
        "def create_x(l1,maxword=200):\n",
        "    '''\n",
        "    \n",
        "    list j√∂n be, ami stringeket tartlamaz\n",
        "    ebb≈ël kell list√°kat tartalmaz√≥ list√°t k√©sz√≠teni :-)\n",
        "    \n",
        "    '''\n",
        "    def str_2_numlist(strin):\n",
        "        \n",
        "        x=strin[1:-1]\n",
        "        x=x.split(\",\")\n",
        "        try:\n",
        "            o=[float(i) for i in x]\n",
        "        except:\n",
        "            o=[0]\n",
        "        return(o)\n",
        "    table=[]\n",
        "    for sent in l1:\n",
        "        sent_float=str_2_numlist(sent)\n",
        "        table.append(sent_float)\n",
        "\n",
        "\n",
        "\n",
        "    x0=[0.0 for _ in range(maxword)]\n",
        "    xx=[]\n",
        "    for sent_t in table:\n",
        "        sent=id_eliminator(sent_t)\n",
        "        if len(sent)<maxword:\n",
        "            o1=x0[0:maxword-len(sent)]+sent\n",
        "        else:\n",
        "            o1=sent[0:maxword]\n",
        "        #print(o1)\n",
        "        xx.append(o1)\n",
        "    return(xx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MNp5ntrxdUsq"
      },
      "outputs": [],
      "source": [
        "def maxpos(l:list):\n",
        "\n",
        "    o=[i.index(max(i)) for i in l]\n",
        "    return(o)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKJpoZyfkm3N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43X1m4YxZDwl",
        "outputId": "dab52278-3e49-48d2-a3f0-0d5bf73619bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ytrain[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOfzs1YeH05g",
        "outputId": "1772bab2-dc14-404f-fd7b-034e6779fdc4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0,\n",
              " 44,\n",
              " 33,\n",
              " 22,\n",
              " 12,\n",
              " 11,\n",
              " 22,\n",
              " 44,\n",
              " 11,\n",
              " 11,\n",
              " 34,\n",
              " 23,\n",
              " 11,\n",
              " 23,\n",
              " 11,\n",
              " 23,\n",
              " 23,\n",
              " 11,\n",
              " 11,\n",
              " 23,\n",
              " 43,\n",
              " 54]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test1=[0,44,33,22,12,11,22,44,11,11,34,23,11,23,11,23,23,11,11,23,43,54,]\n",
        "id_eliminator(test1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tRf3_wt9Bekb"
      },
      "outputs": [],
      "source": [
        "__MAXWORD__=600\n",
        "df_word_list=list(df_train.Words_in_Numbers)\n",
        "max_list=[len(c) for c in df_word_list]\n",
        "xtrain=create_x(df_word_list,maxword=__MAXWORD__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxNMYsVVesOs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UwmBdEkijzv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4O-DzroLiWjk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3JEpjcQSBWtx"
      },
      "outputs": [],
      "source": [
        "set0=set()\n",
        "for xl in xtrain:\n",
        "    xls=set(xl)\n",
        "    set0=set0.union(xls)\n",
        "set0l=list(set0)\n",
        "maxii=max(set0l)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yak5ZOzKChKz"
      },
      "outputs": [],
      "source": [
        "for xl in xtrain:\n",
        "   for i in range(len(xl)):\n",
        "       xl[i]=xl[i]/maxii\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18735.0\n"
          ]
        }
      ],
      "source": [
        "print(maxii)\n",
        "maxii=18735"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V04oYXmEC5FF",
        "outputId": "84b24108-5f12-4ee6-953f-70522223762b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.3672271150253536,\n",
              " 0.04045903389378169,\n",
              " 0.40314918601547906,\n",
              " 0.7782759540966107,\n",
              " 0.707499332799573,\n",
              " 0.5939685081398453,\n",
              " 0.7782759540966107,\n",
              " 0.707499332799573,\n",
              " 0.596050173472111,\n",
              " 0.5796103549506272,\n",
              " 0.5796103549506272,\n",
              " 0.9479583666933546,\n",
              " 0.9479583666933546,\n",
              " 0.0659194021884174,\n",
              " 0.5796103549506272,\n",
              " 0.5796103549506272,\n",
              " 0.0659194021884174,\n",
              " 0.7522284494262076,\n",
              " 0.5957299172671471,\n",
              " 0.8352815585801975,\n",
              " 0.7366426474512944,\n",
              " 0.9781158259941286,\n",
              " 0.04045903389378169,\n",
              " 0.7522284494262076,\n",
              " 0.9468908460101414,\n",
              " 0.8352815585801975,\n",
              " 0.16461168935148118,\n",
              " 0.16461168935148118,\n",
              " 0.596050173472111,\n",
              " 0.5796103549506272,\n",
              " 0.5796103549506272,\n",
              " 0.1314117961035495,\n",
              " 0.5796103549506272,\n",
              " 0.5796103549506272,\n",
              " 0.35052041633306646,\n",
              " 0.19701094208700293,\n",
              " 0.8352815585801975,\n",
              " 0.707499332799573,\n",
              " 0.9781158259941286,\n",
              " 0.707499332799573,\n",
              " 0.9781158259941286,\n",
              " 0.707499332799573,\n",
              " 0.9781158259941286,\n",
              " 0.707499332799573,\n",
              " 0.9781158259941286,\n",
              " 0.5509474246063517,\n",
              " 0.707499332799573,\n",
              " 0.5509474246063517,\n",
              " 0.16461168935148118,\n",
              " 0.05380304243394716,\n",
              " 0.5796103549506272,\n",
              " 0.5796103549506272,\n",
              " 0.35052041633306646,\n",
              " 0.19701094208700293,\n",
              " 0.8352815585801975,\n",
              " 0.707499332799573,\n",
              " 0.9781158259941286,\n",
              " 0.707499332799573,\n",
              " 0.9781158259941286,\n",
              " 0.707499332799573,\n",
              " 0.9781158259941286,\n",
              " 0.707499332799573,\n",
              " 0.9781158259941286,\n",
              " 0.5509474246063517,\n",
              " 0.707499332799573,\n",
              " 0.5509474246063517,\n",
              " 0.16461168935148118,\n",
              " 0.05380304243394716,\n",
              " 0.5796103549506272]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xtrain[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WZSj92FGOebc"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(xtrain, ytrain, test_size=0.1, random_state=43)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "M0Z_th9MhDo_"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WAZfByQCnEhm"
      },
      "outputs": [],
      "source": [
        "y_train_class=maxpos(y_train)\n",
        "y_valid_class=maxpos(y_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRa3SZXHhDlI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4qq3OnkhDiB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v5Hkg-vhDa2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "-_W_1uvDhDTB",
        "outputId": "7a5564ca-917d-4722-afa3-c1c1a5bd9d2c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "id": "59MTn_Fs3SvW"
      },
      "outputs": [],
      "source": [
        "lstm_size=30\n",
        "max_input_length=__MAXWORD__\n",
        "embedding_size=100 #(100: 73%)\n",
        "n_words=18735\n",
        "n_out=len(y_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BS2bWgXsz2zc",
        "outputId": "3b91ff6a-4685-4e30-de56-96b1eda1b9cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18735\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "execution_count": 240,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(n_words)\n",
        "#print(lens1)\n",
        "n_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26U6UXRhmSUE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "uvvPuVNSxNa7"
      },
      "outputs": [],
      "source": [
        "def model_conv():\n",
        "    # Import√°ld a megfelel≈ë r√©tegeket\n",
        "    from tensorflow.keras.layers import Input,Dense,Embedding,LSTM,TimeDistributed, Flatten, Bidirectional, Conv1D, MaxPooling1D, Dropout,Reshape,MaxPooling1D\n",
        "    from tensorflow.keras.models import Model\n",
        "    from tensorflow.keras.optimizers import Adadelta,Adam,SGD,Adamax,RMSprop\n",
        "    from tensorflow.keras.losses import sparse_categorical_crossentropy,categorical_crossentropy, mean_squared_error\n",
        "    from tensorflow.keras import backend as K\n",
        "\n",
        "    K.clear_session\n",
        "    x1= Input(shape=(max_input_length,))\n",
        "\n",
        "    x2=Reshape((__MAXWORD__,1))(x1)\n",
        "    x3=Conv1D(100,kernel_size=(6))(x2)\n",
        "    x4=MaxPooling1D(3)(x3)\n",
        "    x5=Conv1D(100,kernel_size=(3))(x4)\n",
        "    x6=MaxPooling1D(3)(x5)\n",
        "\n",
        "\n",
        "    #conv1=Conv1D(filters=8, kernel_size=2, padding='same', activation='relu')(embedded_x)\n",
        "    #MP=MaxPooling1D(pool_size=1)(conv1)\n",
        "\n",
        "\n",
        "    x7=Flatten()(x6)\n",
        "    Dense_out= Dense(80, activation=\"sigmoid\",kernel_initializer=\"HeNormal\")(x7)\n",
        "\n",
        "    predictions= Dense(n_out, activation=\"softmax\")(Dense_out)\n",
        "    model=Model(inputs=x1, outputs=predictions)\n",
        "    return(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 372,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_lstm():\n",
        "    from tensorflow.keras.layers import Input,Dense,Embedding,LSTM,TimeDistributed, Flatten, Bidirectional, Conv1D, MaxPooling1D, Dropout\n",
        "    from tensorflow.keras.models import Model\n",
        "    from tensorflow.keras.optimizers import Adadelta,Adam,SGD,Adamax\n",
        "    from tensorflow.keras.losses import sparse_categorical_crossentropy,categorical_crossentropy, mean_squared_error\n",
        "    from tensorflow.keras import backend as K\n",
        "\n",
        "    K.clear_session\n",
        "    x= Input(shape=(max_input_length,))\n",
        "    embedded_x=Embedding(n_words,embedding_size, input_length=max_input_length, mask_zero=True)(x)\n",
        "    conv1=Conv1D(filters=64, kernel_size=7, padding='same', activation='relu')(embedded_x)\n",
        "    #MP=MaxPooling1D(pool_size=1)(conv1)\n",
        "    lstm_output= LSTM(lstm_size,return_sequences=True,dropout=0.2,recurrent_dropout=0.2 )(conv1)  # recurrent_dropout=0.2 ?\n",
        "    lstm_output= LSTM(lstm_size,return_sequences=True,dropout=0.2,recurrent_dropout=0.2 )(lstm_output)\n",
        "\n",
        "    lstm_output=Dropout(0.1)(lstm_output)\n",
        "\n",
        "    lstm_output=Flatten()(lstm_output)\n",
        "    \n",
        "    Dense_out= Dense(80, activation=\"relu\",kernel_initializer=\"HeNormal\")(lstm_output)   # activation=\"sigmoid\",kernel_initializer=\"HeNormal\"\n",
        "    Dense_out= Dropout(0.1)(Dense_out)\n",
        "\n",
        "    #Dense_out= Dense(80, activation=\"relu\",kernel_initializer=\"HeNormal\")(Dense_out)\n",
        "    #Dense_out= Dropout(0.1)(Dense_out)\n",
        "\n",
        "\n",
        "    predictions= Dense(n_out, activation=\"softmax\")(Dense_out)\n",
        "    model=Model(inputs=x, outputs=predictions)\n",
        "    return(model)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 373,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_encoderdecoder():\n",
        "    from tensorflow.keras.layers import Input,Dense,Embedding,LSTM,TimeDistributed, Flatten, Bidirectional, Conv1D, MaxPooling1D, Dropout\n",
        "    from tensorflow.keras.models import Model\n",
        "    from tensorflow.keras.optimizers import Adadelta,Adam,SGD,Adamax\n",
        "    from tensorflow.keras.losses import sparse_categorical_crossentropy,categorical_crossentropy, mean_squared_error\n",
        "    from tensorflow.keras import backend as K\n",
        "\n",
        "    K.clear_session\n",
        "    x= Input(shape=(max_input_length,))\n",
        "    d1=Dense(300,activation=\"sigmoid\",kernel_initializer=\"HeNormal\")(x)\n",
        "    d1=Dense(200,activation=\"sigmoid\",kernel_initializer=\"HeNormal\")(d1)\n",
        "    d1=Dense(embedding_size, name=\"encoded\",activation=\"sigmoid\",kernel_initializer=\"HeNormal\")(d1)\n",
        "    d1=Dense(200,activation=\"sigmoid\",kernel_initializer=\"HeNormal\")(d1)\n",
        "    d1=Dense(300,activation=\"sigmoid\",kernel_initializer=\"HeNormal\")(d1)\n",
        "    outlayer=Dense(max_input_length)(d1)\n",
        "\n",
        "   \n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    model=Model(inputs=x, outputs=outlayer)\n",
        "    return(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 374,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_deepnet():\n",
        "    from tensorflow.keras.layers import Input,Dense,Embedding,LSTM,TimeDistributed, Flatten, Bidirectional, Conv1D, MaxPooling1D, Dropout\n",
        "    from tensorflow.keras.models import Model\n",
        "    from tensorflow.keras.optimizers import Adadelta,Adam,SGD,Adamax\n",
        "    from tensorflow.keras.losses import sparse_categorical_crossentropy,categorical_crossentropy, mean_squared_error\n",
        "    from tensorflow.keras import backend as K\n",
        "\n",
        "    K.clear_session\n",
        "    x= Input(shape=(max_input_length,))\n",
        "    d1=Dropout(0.1)(x)\n",
        "    d1=Dense(300,activation=\"sigmoid\",kernel_initializer=\"HeNormal\")(d1)\n",
        "    d1=Dropout(0.1)(d1)\n",
        "    d1=Dense(100,activation=\"sigmoid\",kernel_initializer=\"HeNormal\")(d1)\n",
        "    d1=Dropout(0.1)(d1)\n",
        "    d1=Dense(50,activation=\"sigmoid\",kernel_initializer=\"HeNormal\")(d1)\n",
        "    d1=Dropout(0.1)(d1)\n",
        "    outlayer=Dense(15,activation=\"sigmoid\",kernel_initializer=\"HeNormal\")(d1)\n",
        "\n",
        "   \n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    model=Model(inputs=x, outputs=outlayer)\n",
        "    return(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 375,
      "metadata": {
        "id": "SzJYM8QeJyvI"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 376,
      "metadata": {
        "id": "ACrVf-TbJYDe"
      },
      "outputs": [],
      "source": [
        "#train_x = np.asarray(xtrain)\n",
        "#train_y = np.asarray(ytrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lj_fAh_eKaSl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 377,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJSGfsxkm9zJ",
        "outputId": "22019f2a-f57b-4777-d4f7-8ad47c402ea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_addons in c:\\users\\sipocz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.15.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in c:\\users\\sipocz\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow_addons) (2.13.3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\n",
            "You should consider upgrading via the 'c:\\users\\sipocz\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 378,
      "metadata": {
        "id": "xytusjy0IopL"
      },
      "outputs": [],
      "source": [
        "import tensorflow_addons as tfa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 379,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_dict={\"lstm\":model_lstm,\"deepnet\":model_deepnet,\"conv\":model_conv, \"encoderdecoder\":model_encoderdecoder}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 380,
      "metadata": {},
      "outputs": [],
      "source": [
        "_MODEL_TYPE_=\"lstm\"\n",
        "model=model_dict[_MODEL_TYPE_]()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 381,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQpADS6gMHmd",
        "outputId": "5e299e72-57e9-466a-aee9-ea4f3d179df9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_26 (InputLayer)        [(None, 600)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_8 (Embedding)      (None, 600, 100)          1873500   \n",
            "_________________________________________________________________\n",
            "conv1d_14 (Conv1D)           (None, 600, 64)           44864     \n",
            "_________________________________________________________________\n",
            "lstm_15 (LSTM)               (None, 600, 30)           11400     \n",
            "_________________________________________________________________\n",
            "lstm_16 (LSTM)               (None, 600, 30)           7320      \n",
            "_________________________________________________________________\n",
            "dropout_36 (Dropout)         (None, 600, 30)           0         \n",
            "_________________________________________________________________\n",
            "flatten_14 (Flatten)         (None, 18000)             0         \n",
            "_________________________________________________________________\n",
            "dense_77 (Dense)             (None, 80)                1440080   \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 15)                1215      \n",
            "=================================================================\n",
            "Total params: 3,378,379\n",
            "Trainable params: 3,378,379\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 382,
      "metadata": {
        "id": "RWIM4DP36S2L"
      },
      "outputs": [],
      "source": [
        "# Loss \n",
        "\n",
        "\n",
        "\n",
        "loss =categorical_crossentropy #mean_squared_error #categorical_crossentropy \n",
        "if _MODEL_TYPE_==\"encoderdecoder\":\n",
        "    \n",
        "    loss=mean_squared_error\n",
        "    optimizer = Adam(learning_rate=0.001) #ADAM\n",
        "    model.compile(optimizer=optimizer,loss=loss )\n",
        "\n",
        "elif _MODEL_TYPE_==\"lstm\":\n",
        "    f1score=tfa.metrics.F1Score(num_classes=15)\n",
        "    # Optimizer\n",
        "    optimizer = RMSprop(learning_rate=0.001) #RMSprop\n",
        " \n",
        "    # Compilation\n",
        "    #############\n",
        "    model.compile(optimizer=optimizer,loss=loss, metrics=[\"accuracy\",f1score])\n",
        "\n",
        "elif _MODEL_TYPE_==\"deepnet\":\n",
        "    f1score=tfa.metrics.F1Score(num_classes=15)\n",
        "    # Optimizer\n",
        "    optimizer = Adam(learning_rate=0.001) #RMSprop\n",
        "    loss=categorical_crossentropy\n",
        "    # Compilation\n",
        "    #############\n",
        "    model.compile(optimizer=optimizer,loss=loss, metrics=[\"accuracy\",f1score])\n",
        "\n",
        "elif _MODEL_TYPE_==\"conv\":\n",
        "    f1score=tfa.metrics.F1Score(num_classes=15)\n",
        "    # Optimizer\n",
        "    optimizer = RMSprop(learning_rate=0.001) #RMSprop\n",
        " \n",
        "    # Compilation\n",
        "    #############\n",
        "    model.compile(optimizer=optimizer,loss=loss, metrics=[\"accuracy\",f1score])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 383,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st2F_x9FuMEW",
        "outputId": "6e28b1b5-c4f8-4bbb-ab0e-80a5db794495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41065\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "41065"
            ]
          },
          "execution_count": 383,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(len(y_train))\n",
        "len(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 384,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBZsCDc3g_aH",
        "outputId": "60f0dd29-a1a0-4a3c-80e5-5a55ba30ed74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]"
            ]
          },
          "execution_count": 384,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 385,
      "metadata": {
        "id": "kexCNLWBmsA9"
      },
      "outputs": [],
      "source": [
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "ReduceLROnPlateau = ReduceLROnPlateau(factor=0.9,\n",
        "                                     min_lr = 0.0001,\n",
        "                                     monitor = 'val_loss',\n",
        "                                     verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 391,
      "metadata": {
        "id": "7J2K6EXIgYQG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "model_name=\"PoLaCa_LSTM\"\n",
        "def scheduler(epoch, lr):\n",
        "    return 0.01\n",
        "        \n",
        "    '''\n",
        "    maxx=0.001\n",
        "    minn=0.00001\n",
        "    frekvency=5\n",
        "    o=(epoch % frekvency)/frekvency * (maxx-minn)+minn\n",
        "    '''\n",
        "    print(f\"lr--{lr}\")\n",
        "    return lr\n",
        "\n",
        "        \n",
        "    if epoch<50:\n",
        "        return 0.001\n",
        "    elif epoch <100:\n",
        "        return 0.001\n",
        "    elif epoch <1200:\n",
        "        return 0.0001\n",
        "    return 0.001\n",
        "    \n",
        "callback_LR = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "if _MODEL_TYPE_==\"encoderdecoder\":\n",
        "\n",
        "    callbacks = [callback_LR,\n",
        "            \n",
        "            #savemodela,\n",
        "            ModelCheckpoint(filepath=model_name+\"_LOSS_{loss:.5f}.hdf5\", monitor='loss',\n",
        "                            verbose=1, save_best_only=True, mode='min')]\n",
        "elif _MODEL_TYPE_==\"conv\":\n",
        "\n",
        "\n",
        "    callbacks = [callback_LR,\n",
        "            \n",
        "            #savemodela,\n",
        "            ModelCheckpoint(filepath=model_name+\"_LOSS_{loss:.5f}_VACC_{val_accuracy:.4f}_VF1.hdf5\", monitor='loss',\n",
        "                            verbose=1, save_best_only=True, mode='min')]\n",
        "\n",
        "elif _MODEL_TYPE_==\"deepnet\":\n",
        "\n",
        "\n",
        "    callbacks = [callback_LR,\n",
        "            \n",
        "            #savemodela,\n",
        "            ModelCheckpoint(filepath=model_name+\"_LOSS_{loss:.5f}_VACC_{val_accuracy:.4f}_VF1.hdf5\", monitor='loss',\n",
        "                            verbose=1, save_best_only=True, mode='min')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 387,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXmswKBnKxS3",
        "outputId": "ad1f44e6-fe6b-4688-a205-6524361b400d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Could Not Find c:\\Users\\sipocz\\Downloads\\programming_language_classification\\*.hdf5\n"
          ]
        }
      ],
      "source": [
        "if _OS_==\"linux\":\n",
        "    !rm *.hdf5\n",
        "if _OS_==\"windows\":\n",
        "    !del *.hdf5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 388,
      "metadata": {},
      "outputs": [],
      "source": [
        "#    model.load_weights(\"./PoLaCa_conv_LOSS_0.76694_VACC_0.0000_VF1.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 392,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op-I834SFpUX",
        "outputId": "002ee09f-9772-498c-a038-5c25ff7e4a7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "lr--0.0010000000474974513\n",
            " 622/1284 [=============>................] - ETA: 7:34 - loss: 2.0799 - accuracy: 0.2693 - f1_score: 0.0431"
          ]
        }
      ],
      "source": [
        "# Illessz√ºk az adatra a modellt\n",
        "if _MODEL_TYPE_==\"lstm\":\n",
        "        history=model.fit(\n",
        "                x=x_train,\n",
        "                y=y_train, \n",
        "                epochs=200, \n",
        "                batch_size=32,\n",
        "                validation_data=(x_valid,y_valid) ,         \n",
        "                callbacks=[ReduceLROnPlateau,callbacks]          \n",
        "                )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'o' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-340-5097586b7823>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m_MODEL_TYPE_\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"conv\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m         history=model.fit(\n\u001b[0m\u001b[0;32m      3\u001b[0m                 \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                 \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1088\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1090\u001b[1;33m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1091\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_begin\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Only convert once.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m           \u001b[0mnumpy_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    412\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_begin\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m   1903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# new API\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1904\u001b[0m       \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1905\u001b[1;33m       \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1906\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Support for old API for backward compatibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1907\u001b[0m       \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-338-400f2ab13d64>\u001b[0m in \u001b[0;36mscheduler\u001b[1;34m(epoch, lr)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfrekvency\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mfrekvency\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmaxx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mminn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mminn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     '''\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"lr--{o}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'o' is not defined"
          ]
        }
      ],
      "source": [
        "if _MODEL_TYPE_==\"conv\":\n",
        "        history=model.fit(\n",
        "                x=x_train,\n",
        "                y=y_train, \n",
        "                epochs=400, \n",
        "                batch_size=32,\n",
        "                validation_data=(x_valid,y_valid) ,         \n",
        "                callbacks=[callbacks]          \n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-261-4836fcc7c89f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history=model.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;31m# Legacy graph support is contained in `training_v1.Model`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fit'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2590\u001b[0m     \u001b[1;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2591\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2592\u001b[1;33m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[0;32m   2593\u001b[0m                          \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2594\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
            "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ],
      "source": [
        "history=model.fit(\n",
        "        x=x_train,\n",
        "        y=x_train, \n",
        "        epochs=200, \n",
        "        batch_size=32,\n",
        "        validation_data=(x_valid,x_valid) ,         \n",
        "        callbacks=[callbacks]          \n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UV9VOXARdCK"
      },
      "outputs": [],
      "source": [
        "model.save_weights(\"model1.hdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlQsg0UmbhaM"
      },
      "outputs": [],
      "source": [
        "model.load_weights(\"./PoLaCa_LOSS_1.51307_VACC_0.4420_VF1.xhdf5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_CHGgYja_bB"
      },
      "outputs": [],
      "source": [
        "pred=model.predict(x_train,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwAtCYVLcXFD"
      },
      "outputs": [],
      "source": [
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loCl2-qmA6SL"
      },
      "outputs": [],
      "source": [
        "def maxpos(l:list):\n",
        "\n",
        "    o=[i.index(max(i)) for i in l]\n",
        "    print(o)\n",
        "    return(o)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZmA5cOmcoKS"
      },
      "outputs": [],
      "source": [
        "y_pred_list=[list(y_pred_i) for y_pred_i in pred] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fy-b5ldQbntI"
      },
      "outputs": [],
      "source": [
        "yyy_train_cat=maxpos(y_train)\n",
        "yyy_pred_cat=maxpos(y_pred_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3H3sjkc3lGp"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(yyy_train_cat, yyy_pred_cat, 'ro')\n",
        "plt.axis([0, 6, 0, 20])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIFRZ753bMNi"
      },
      "outputs": [],
      "source": [
        "def show_difference(pred,ytrain,df,verbose=False):\n",
        "    ecounter=0\n",
        "    for i in range(len(pred)):\n",
        "        predi=pred[i]\n",
        "        traini=y_train[i]\n",
        "        if maxpos(traini)!=maxpos(predi):\n",
        "            ecounter+=1\n",
        "            if verbose:\n",
        "                print(f\"{i}, {predi}, {traini}\")\n",
        "                print(f\"---Text: {df.iloc[i].text}\")\n",
        "    print(f\"Hiba sz√°m: {ecounter:6}, ar√°ny: {ecounter/len(df)*100}% \")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWKt2DCcFbKc"
      },
      "outputs": [],
      "source": [
        "show_difference(pred,ytrain,df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x39xe3TmGHJ_"
      },
      "outputs": [],
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlKyrRqfG6GP"
      },
      "source": [
        "### Model usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nu6ZvqIwlz_R"
      },
      "outputs": [],
      "source": [
        "if _OS_==\"linux\":\n",
        "    test_converted=\"https://github.com/sipocz/Programming_language_classification/raw/7cf3cc4e8397c150b45e2a5abb7b0e9b1e3d8ab7/orig/test_id.csv\"\n",
        "    !wget $test_converted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvmmKvBIF4n8"
      },
      "outputs": [],
      "source": [
        "test_df=pd.read_csv(\"./test_id_big.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mc0vyTmcHRvY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9277\n"
          ]
        }
      ],
      "source": [
        "print(len(test_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5utaqxGNHU7y"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>code</th>\n",
              "      <th>Word_list</th>\n",
              "      <th>Words_in_Numbers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>10684</td>\n",
              "      <td>28 = 22 + 23 + 24\\n\\n 33 = 32 + 23 + 24\\n\\n 49...</td>\n",
              "      <td>_number_ _equal_ _number_ _plus_ _number_ _plu...</td>\n",
              "      <td>[13255, 7553, 13255, 7080, 13255, 7080, 13255,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>17536</td>\n",
              "      <td>this.path = path;\\n\\n       this.estimat...</td>\n",
              "      <td>_this_ _point_ _PATH_ _equal_ _PATH_ _semicolo...</td>\n",
              "      <td>[10956, 14093, 17212, 7553, 17212, 11167, 1085...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>26383</td>\n",
              "      <td>{\\n\\n                     ...</td>\n",
              "      <td>_brace_open_ _new_line_ _new_line_ _TMP_ _plus...</td>\n",
              "      <td>[2769, 10859, 10859, 3397, 7080, 7553, 10322, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>29090</td>\n",
              "      <td>/**\\n\\n  * Class for converting from \"any\" bas...</td>\n",
              "      <td>_division_ _star_ _star_ _new_line_ _new_line_...</td>\n",
              "      <td>[17760, 13892, 13892, 10859, 10859, 13892, 100...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>10482</td>\n",
              "      <td>{ cout&lt;&lt;\"Destructing base \\n\"; }      ...</td>\n",
              "      <td>_brace_open_ _COUT_ _smaller_sign_ _smaller_si...</td>\n",
              "      <td>[2769, 10816, 15723, 15723, 10322, 4477, 4186,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>11952</td>\n",
              "      <td>X·µ¢ = a + (b-a)*rand()\\n\\n         Œ£ +=...</td>\n",
              "      <td>_X·µ¢_ _equal_ _A_ _plus_ _bracket_open_ _B_ _mi...</td>\n",
              "      <td>[7656, 7553, 2228, 7080, 15649, 8455, 12420, 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>33227</td>\n",
              "      <td>\\t}\\n\\n }\\n\\n func assertRot13Output(t *testin...</td>\n",
              "      <td>_tab_ _brace_close_ _new_line_ _new_line_ _bra...</td>\n",
              "      <td>[13175, 2462, 10859, 10859, 2462, 10859, 10859...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>87635</td>\n",
              "      <td>if (!super.equals(object)) return false;...</td>\n",
              "      <td>_if_ _bracket_open_ _exclamation_ _super_ _poi...</td>\n",
              "      <td>[10569, 15649, 1164, 4661, 14093, 5473, 15649,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>29183</td>\n",
              "      <td>node.Level != node...</td>\n",
              "      <td>_NODE_ _point_ _LEVEL_ _exclamation_ _equal_ _...</td>\n",
              "      <td>[12180, 14093, 17510, 1164, 7553, 12180, 14093...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>93219</td>\n",
              "      <td>}\\n\\n /** Test function\\n\\n   * @returns None\\...</td>\n",
              "      <td>_brace_close_ _new_line_ _new_line_ _division_...</td>\n",
              "      <td>[2462, 10859, 10859, 17760, 13892, 13892, 5281...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>11864</td>\n",
              "      <td>* @param l the left index of the range to...</td>\n",
              "      <td>_star_ _at_sign_ _PARAM_ _L_ _THE_ _left_ _IND...</td>\n",
              "      <td>[13892, 16321, 13029, 11115, 13053, 8818, 5140...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>40466</td>\n",
              "      <td>}while(ch=='y');\\n\\n     out.close();\\n\\n ...</td>\n",
              "      <td>_brace_close_ _while_ _bracket_open_ _CH_ _equ...</td>\n",
              "      <td>[2462, 13488, 15649, 14703, 7553, 7553, 10322,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>62931</td>\n",
              "      <td># Predict Output \\n\\n predicted= predict(fit,x...</td>\n",
              "      <td>_hashmark_ _PREDICT_ _OUTPUT_ _new_line_ _new_...</td>\n",
              "      <td>[17614, 3283, 16951, 10859, 10859, 17713, 7553...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>21621</td>\n",
              "      <td>x = removes();\\n\\n             pri...</td>\n",
              "      <td>_X_ _equal_ _REMOVES_ _bracket_open_ _bracket_...</td>\n",
              "      <td>[9018, 7553, 18204, 15649, 3084, 11167, 10859,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>24775</td>\n",
              "      <td>// 'Hello World'\\n</td>\n",
              "      <td>_division_ _division_ _string_ _HELLO_ _string...</td>\n",
              "      <td>[17760, 17760, 10322, 14754, 10322, 10859]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>70170</td>\n",
              "      <td>import java.util.ArrayList;\\n\\n import javax.i...</td>\n",
              "      <td>_import_ _JAVA_ _point_ _UTIL_ _point_ _ARRAYL...</td>\n",
              "      <td>[2656, 7628, 14093, 17429, 14093, 8678, 11167,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>12357</td>\n",
              "      <td>size_t idx = word[index] - 'a';\\n\\n   ...</td>\n",
              "      <td>_SIZE_ _underline_ _T_ _IDX_ _equal_ _WORD_ _c...</td>\n",
              "      <td>[18083, 6315, 6611, 17517, 7553, 7509, 6567, 5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>25732</td>\n",
              "      <td>private int Partition(T[] array, IComp...</td>\n",
              "      <td>_private_ _int_ _PARTITION_ _bracket_open_ _T_...</td>\n",
              "      <td>[13136, 12481, 563, 15649, 6611, 6567, 1008, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>16981</td>\n",
              "      <td>})\\n\\n   })\\n\\n })\\n</td>\n",
              "      <td>_brace_close_ _bracket_close_ _new_line_ _new_...</td>\n",
              "      <td>[2462, 3084, 10859, 10859, 2462, 3084, 10859, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>10841</td>\n",
              "      <td>a = c * ((d &lt;&lt; 1) - c);\\n\\n     b = c * c ...</td>\n",
              "      <td>_A_ _equal_ _C_ _star_ _bracket_open_ _bracket...</td>\n",
              "      <td>[2228, 7553, 5853, 13892, 15649, 15649, 9867, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>51621</td>\n",
              "      <td>\\n\\n             var m...</td>\n",
              "      <td>_new_line_ _new_line_ _var_ _MINIMUM_ _equal_ ...</td>\n",
              "      <td>[10859, 10859, 6880, 9161, 7553, 18087, 10859,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>40668</td>\n",
              "      <td>\\treturn math.Sqrt(res)\\n\\n }\\n</td>\n",
              "      <td>_tab_ _return_ _MATH_ _point_ _SQRT_ _bracket_...</td>\n",
              "      <td>[13175, 2578, 5165, 14093, 10828, 15649, 8722,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>10870</td>\n",
              "      <td>\\t\\tchar := word[i]\\n\\n \\t\\tnumberOfUsage := u...</td>\n",
              "      <td>_tab_ _tab_ _char_ _colon_ _equal_ _WORD_ _cro...</td>\n",
              "      <td>[13175, 13175, 2631, 18475, 7553, 7509, 6567, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>29687</td>\n",
              "      <td>using System;\\n\\n using FluentAssertions;\\n\\n ...</td>\n",
              "      <td>_using_ _SYSTEM_ _semicolon_ _new_line_ _new_l...</td>\n",
              "      <td>[4654, 5841, 11167, 10859, 10859, 4654, 5758, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>10008</td>\n",
              "      <td>while (mmh.Count &gt; 0)\\n\\n         ...</td>\n",
              "      <td>_while_ _bracket_open_ _MMH_ _point_ _COUNT_ _...</td>\n",
              "      <td>[13488, 15649, 2520, 14093, 14819, 12166, 1325...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>11708</td>\n",
              "      <td>}\\n</td>\n",
              "      <td>_brace_close_ _new_line_</td>\n",
              "      <td>[2462, 10859]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>84005</td>\n",
              "      <td>*/\\n\\n         std::string encrypt (c...</td>\n",
              "      <td>_star_ _division_ _new_line_ _new_line_ _STD_ ...</td>\n",
              "      <td>[13892, 17760, 10859, 10859, 4234, 18475, 1847...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>26638</td>\n",
              "      <td># Decimal value of 110011 is 51\\n\\n puts 'Deci...</td>\n",
              "      <td>_hashmark_ _DECIMAL_ _VALUE_ _OF_ _number_ _is...</td>\n",
              "      <td>[17614, 10955, 9627, 9373, 13255, 3455, 13255,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>30137</td>\n",
              "      <td>var vertex4 = graph.AddVertex(40);...</td>\n",
              "      <td>_var_ _VERTEX_ _number_ _equal_ _GRAPH_ _point...</td>\n",
              "      <td>[6880, 12763, 13255, 7553, 13552, 14093, 15983...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>16869</td>\n",
              "      <td>std::function&lt;double(double)&gt; func = [](do...</td>\n",
              "      <td>_STD_ _colon_ _colon_ _function_ _smaller_sign...</td>\n",
              "      <td>[4234, 18475, 18475, 7152, 15723, 2395, 15649,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0     id                                               code  \\\n",
              "0            0  10684  28 = 22 + 23 + 24\\n\\n 33 = 32 + 23 + 24\\n\\n 49...   \n",
              "1            1  17536        this.path = path;\\n\\n       this.estimat...   \n",
              "2            2  26383                      {\\n\\n                     ...   \n",
              "3            3  29090  /**\\n\\n  * Class for converting from \"any\" bas...   \n",
              "4            4  10482          { cout<<\"Destructing base \\n\"; }      ...   \n",
              "5            5  11952          X·µ¢ = a + (b-a)*rand()\\n\\n         Œ£ +=...   \n",
              "6            6  33227  \\t}\\n\\n }\\n\\n func assertRot13Output(t *testin...   \n",
              "7            7  87635        if (!super.equals(object)) return false;...   \n",
              "8            8  29183                              node.Level != node...   \n",
              "9            9  93219  }\\n\\n /** Test function\\n\\n   * @returns None\\...   \n",
              "10          10  11864       * @param l the left index of the range to...   \n",
              "11          11  40466      }while(ch=='y');\\n\\n     out.close();\\n\\n ...   \n",
              "12          12  62931  # Predict Output \\n\\n predicted= predict(fit,x...   \n",
              "13          13  21621              x = removes();\\n\\n             pri...   \n",
              "14          14  24775                                 // 'Hello World'\\n   \n",
              "15          15  70170  import java.util.ArrayList;\\n\\n import javax.i...   \n",
              "16          16  12357          size_t idx = word[index] - 'a';\\n\\n   ...   \n",
              "17          17  25732          private int Partition(T[] array, IComp...   \n",
              "18          18  16981                               })\\n\\n   })\\n\\n })\\n   \n",
              "19          19  10841      a = c * ((d << 1) - c);\\n\\n     b = c * c ...   \n",
              "20          20  51621                          \\n\\n             var m...   \n",
              "21          21  40668                    \\treturn math.Sqrt(res)\\n\\n }\\n   \n",
              "22          22  10870  \\t\\tchar := word[i]\\n\\n \\t\\tnumberOfUsage := u...   \n",
              "23          23  29687  using System;\\n\\n using FluentAssertions;\\n\\n ...   \n",
              "24          24  10008              while (mmh.Count > 0)\\n\\n         ...   \n",
              "25          25  11708                                                }\\n   \n",
              "26          26  84005           */\\n\\n         std::string encrypt (c...   \n",
              "27          27  26638  # Decimal value of 110011 is 51\\n\\n puts 'Deci...   \n",
              "28          28  30137              var vertex4 = graph.AddVertex(40);...   \n",
              "29          29  16869      std::function<double(double)> func = [](do...   \n",
              "\n",
              "                                            Word_list  \\\n",
              "0   _number_ _equal_ _number_ _plus_ _number_ _plu...   \n",
              "1   _this_ _point_ _PATH_ _equal_ _PATH_ _semicolo...   \n",
              "2   _brace_open_ _new_line_ _new_line_ _TMP_ _plus...   \n",
              "3   _division_ _star_ _star_ _new_line_ _new_line_...   \n",
              "4   _brace_open_ _COUT_ _smaller_sign_ _smaller_si...   \n",
              "5   _X·µ¢_ _equal_ _A_ _plus_ _bracket_open_ _B_ _mi...   \n",
              "6   _tab_ _brace_close_ _new_line_ _new_line_ _bra...   \n",
              "7   _if_ _bracket_open_ _exclamation_ _super_ _poi...   \n",
              "8   _NODE_ _point_ _LEVEL_ _exclamation_ _equal_ _...   \n",
              "9   _brace_close_ _new_line_ _new_line_ _division_...   \n",
              "10  _star_ _at_sign_ _PARAM_ _L_ _THE_ _left_ _IND...   \n",
              "11  _brace_close_ _while_ _bracket_open_ _CH_ _equ...   \n",
              "12  _hashmark_ _PREDICT_ _OUTPUT_ _new_line_ _new_...   \n",
              "13  _X_ _equal_ _REMOVES_ _bracket_open_ _bracket_...   \n",
              "14  _division_ _division_ _string_ _HELLO_ _string...   \n",
              "15  _import_ _JAVA_ _point_ _UTIL_ _point_ _ARRAYL...   \n",
              "16  _SIZE_ _underline_ _T_ _IDX_ _equal_ _WORD_ _c...   \n",
              "17  _private_ _int_ _PARTITION_ _bracket_open_ _T_...   \n",
              "18  _brace_close_ _bracket_close_ _new_line_ _new_...   \n",
              "19  _A_ _equal_ _C_ _star_ _bracket_open_ _bracket...   \n",
              "20  _new_line_ _new_line_ _var_ _MINIMUM_ _equal_ ...   \n",
              "21  _tab_ _return_ _MATH_ _point_ _SQRT_ _bracket_...   \n",
              "22  _tab_ _tab_ _char_ _colon_ _equal_ _WORD_ _cro...   \n",
              "23  _using_ _SYSTEM_ _semicolon_ _new_line_ _new_l...   \n",
              "24  _while_ _bracket_open_ _MMH_ _point_ _COUNT_ _...   \n",
              "25                          _brace_close_ _new_line_    \n",
              "26  _star_ _division_ _new_line_ _new_line_ _STD_ ...   \n",
              "27  _hashmark_ _DECIMAL_ _VALUE_ _OF_ _number_ _is...   \n",
              "28  _var_ _VERTEX_ _number_ _equal_ _GRAPH_ _point...   \n",
              "29  _STD_ _colon_ _colon_ _function_ _smaller_sign...   \n",
              "\n",
              "                                     Words_in_Numbers  \n",
              "0   [13255, 7553, 13255, 7080, 13255, 7080, 13255,...  \n",
              "1   [10956, 14093, 17212, 7553, 17212, 11167, 1085...  \n",
              "2   [2769, 10859, 10859, 3397, 7080, 7553, 10322, ...  \n",
              "3   [17760, 13892, 13892, 10859, 10859, 13892, 100...  \n",
              "4   [2769, 10816, 15723, 15723, 10322, 4477, 4186,...  \n",
              "5   [7656, 7553, 2228, 7080, 15649, 8455, 12420, 2...  \n",
              "6   [13175, 2462, 10859, 10859, 2462, 10859, 10859...  \n",
              "7   [10569, 15649, 1164, 4661, 14093, 5473, 15649,...  \n",
              "8   [12180, 14093, 17510, 1164, 7553, 12180, 14093...  \n",
              "9   [2462, 10859, 10859, 17760, 13892, 13892, 5281...  \n",
              "10  [13892, 16321, 13029, 11115, 13053, 8818, 5140...  \n",
              "11  [2462, 13488, 15649, 14703, 7553, 7553, 10322,...  \n",
              "12  [17614, 3283, 16951, 10859, 10859, 17713, 7553...  \n",
              "13  [9018, 7553, 18204, 15649, 3084, 11167, 10859,...  \n",
              "14         [17760, 17760, 10322, 14754, 10322, 10859]  \n",
              "15  [2656, 7628, 14093, 17429, 14093, 8678, 11167,...  \n",
              "16  [18083, 6315, 6611, 17517, 7553, 7509, 6567, 5...  \n",
              "17  [13136, 12481, 563, 15649, 6611, 6567, 1008, 1...  \n",
              "18  [2462, 3084, 10859, 10859, 2462, 3084, 10859, ...  \n",
              "19  [2228, 7553, 5853, 13892, 15649, 15649, 9867, ...  \n",
              "20  [10859, 10859, 6880, 9161, 7553, 18087, 10859,...  \n",
              "21  [13175, 2578, 5165, 14093, 10828, 15649, 8722,...  \n",
              "22  [13175, 13175, 2631, 18475, 7553, 7509, 6567, ...  \n",
              "23  [4654, 5841, 11167, 10859, 10859, 4654, 5758, ...  \n",
              "24  [13488, 15649, 2520, 14093, 14819, 12166, 1325...  \n",
              "25                                      [2462, 10859]  \n",
              "26  [13892, 17760, 10859, 10859, 4234, 18475, 1847...  \n",
              "27  [17614, 10955, 9627, 9373, 13255, 3455, 13255,...  \n",
              "28  [6880, 12763, 13255, 7553, 13552, 14093, 15983...  \n",
              "29  [4234, 18475, 18475, 7152, 15723, 2395, 15649,...  "
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df.head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykk17oAEoPwM"
      },
      "outputs": [],
      "source": [
        "__MAXWORD__=600\n",
        "test_word_list=list(test_df.Words_in_Numbers)\n",
        "x_test=create_x(test_word_list,maxword=__MAXWORD__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "maxii=18735"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for xl in x_test:\n",
        "   for i in range(len(xl)):\n",
        "       xl[i]=xl[i]/maxii\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NoH4Fu519Nz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.1314117961035495,\n",
              " 0.5796103549506272]"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test[25]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1hMxgBCpjwV"
      },
      "outputs": [],
      "source": [
        "model.load_weights(\"./PoLaCa_conv_LOSS_0.46274_VACC_0.0001_VF1.hdf5\") #itt majd j√≥t kell bet√∂lteni"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg0DqmUWoj5s"
      },
      "outputs": [],
      "source": [
        "y_pred=model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mp8QI7WXqbK_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[5.52869096e-06, 1.08218437e-05, 9.98559892e-01, 1.13484496e-03,\n",
              "        3.66742285e-07, 3.15643993e-05, 7.45387069e-06, 1.99082133e-05,\n",
              "        1.89279206e-07, 1.72566273e-04, 1.33953847e-07, 4.34632202e-05,\n",
              "        1.40670625e-06, 1.81350810e-08, 1.19212964e-05],\n",
              "       [2.03670515e-03, 9.61024895e-08, 9.96072531e-01, 2.39797984e-04,\n",
              "        1.69423165e-05, 3.16986153e-08, 5.65549317e-06, 6.44333113e-07,\n",
              "        5.64600850e-06, 6.77153755e-09, 3.91381800e-05, 1.41747075e-03,\n",
              "        3.26200025e-05, 3.53263396e-09, 1.32652756e-04],\n",
              "       [6.85437908e-03, 1.79041803e-01, 4.02070671e-01, 4.26064292e-03,\n",
              "        1.72006875e-01, 1.05456593e-05, 1.65373611e-04, 1.67287968e-03,\n",
              "        2.11145356e-01, 2.40453033e-07, 1.74721666e-02, 9.81310382e-04,\n",
              "        1.36643319e-08, 1.56171212e-03, 2.75610341e-03],\n",
              "       [1.51119451e-03, 6.80159125e-03, 3.08674067e-01, 2.70964116e-01,\n",
              "        4.41107899e-02, 3.73238907e-03, 8.54502214e-05, 3.90357822e-02,\n",
              "        2.83792764e-01, 3.38169979e-03, 1.33111943e-02, 1.82910617e-02,\n",
              "        1.89861850e-04, 2.04421906e-03, 4.07393416e-03],\n",
              "       [1.71293723e-05, 5.05966025e-09, 1.06090694e-04, 3.73830256e-09,\n",
              "        7.24379612e-10, 5.75336259e-08, 4.28069719e-10, 1.22977826e-06,\n",
              "        4.27874693e-06, 1.18688081e-06, 3.86557913e-05, 9.95626807e-01,\n",
              "        4.20061266e-03, 2.97921588e-07, 3.58064631e-06],\n",
              "       [1.31327286e-02, 7.70903602e-02, 5.52816838e-02, 2.50692010e-01,\n",
              "        1.01394080e-01, 3.17805982e-03, 9.95980799e-02, 2.22714851e-03,\n",
              "        3.74489115e-03, 2.03086957e-02, 3.47796418e-02, 3.25285792e-01,\n",
              "        1.21319424e-02, 7.44217774e-04, 4.10631706e-04],\n",
              "       [5.21124061e-03, 1.75467834e-01, 5.43764532e-01, 3.71870515e-03,\n",
              "        1.03302291e-02, 1.60686597e-02, 3.16662132e-03, 6.82583312e-03,\n",
              "        1.98119115e-02, 1.89879537e-02, 1.48616340e-02, 1.00871339e-01,\n",
              "        6.66977689e-02, 2.95192213e-03, 1.12637859e-02],\n",
              "       [1.80185668e-03, 1.48140869e-04, 5.73487999e-03, 1.52403198e-04,\n",
              "        1.03139660e-04, 7.76913538e-08, 1.21498841e-03, 3.68189928e-03,\n",
              "        2.31539001e-04, 2.10359767e-02, 7.08119897e-03, 9.47340608e-01,\n",
              "        1.12274718e-02, 9.57076991e-05, 1.50185020e-04],\n",
              "       [5.94578705e-06, 1.42921992e-02, 8.70349759e-05, 1.58678312e-02,\n",
              "        1.67101342e-02, 1.63203094e-05, 2.49509242e-07, 4.52368986e-05,\n",
              "        2.54608894e-04, 1.69765175e-04, 1.20953227e-04, 9.52177465e-01,\n",
              "        1.50956057e-05, 1.93402753e-04, 4.38631287e-05],\n",
              "       [7.18100753e-04, 1.90193683e-03, 9.06144500e-01, 1.94851673e-04,\n",
              "        1.35629615e-02, 7.77466412e-05, 2.26992179e-05, 6.37532771e-02,\n",
              "        1.04406048e-04, 9.64741162e-07, 9.62898193e-04, 3.22475005e-03,\n",
              "        4.31201234e-03, 4.94518190e-07, 5.01830084e-03],\n",
              "       [3.16846883e-03, 1.19156651e-01, 2.56284505e-01, 1.14343159e-01,\n",
              "        3.78782935e-02, 9.13925096e-03, 4.88125645e-02, 1.18884355e-01,\n",
              "        1.13488823e-01, 1.89493988e-02, 1.66857466e-02, 7.91290477e-02,\n",
              "        3.28061990e-02, 1.50986742e-02, 1.61748342e-02],\n",
              "       [5.43658571e-05, 2.14775130e-01, 9.08638313e-02, 1.08864784e-04,\n",
              "        7.19327654e-04, 4.36952320e-07, 6.64943158e-08, 6.84072316e-01,\n",
              "        5.25723817e-03, 2.66459028e-06, 4.04374721e-03, 3.99378223e-05,\n",
              "        5.00036149e-05, 1.95923349e-06, 1.00884108e-05],\n",
              "       [6.67068107e-08, 2.24982898e-07, 7.96910538e-09, 5.58746882e-10,\n",
              "        3.64858477e-09, 3.10746664e-08, 2.48776395e-08, 8.42179729e-11,\n",
              "        4.41941779e-07, 4.33010900e-05, 3.02156150e-06, 9.99950409e-01,\n",
              "        2.25947383e-06, 2.88061159e-07, 5.81244275e-10],\n",
              "       [2.42787719e-05, 1.35618702e-01, 7.15696096e-01, 1.50588879e-04,\n",
              "        1.99259911e-03, 2.92331376e-03, 9.58264354e-05, 3.15681868e-03,\n",
              "        1.12477548e-01, 4.16836614e-04, 2.05249908e-05, 5.06454555e-04,\n",
              "        1.46979051e-08, 1.28664497e-05, 2.69074775e-02],\n",
              "       [4.75285124e-05, 4.21215809e-05, 9.53953683e-01, 1.18809771e-08,\n",
              "        8.76786886e-04, 2.76872561e-05, 6.90038678e-06, 8.29100088e-07,\n",
              "        1.89331869e-04, 6.84796134e-04, 6.45391410e-04, 4.34193388e-02,\n",
              "        3.29521725e-08, 2.76109716e-07, 1.05369312e-04]], dtype=float32)"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred[15:30]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0ks9CeyrWSJ"
      },
      "outputs": [],
      "source": [
        "def maxpos(l:list):\n",
        "\n",
        "    o=[i.index(max(i)) for i in l]\n",
        "    print(o)\n",
        "    return(o)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0tMIrfpqYip"
      },
      "outputs": [],
      "source": [
        "def ylabel_deconvert_5(sentiment):\n",
        "    yout_index=maxpos(sentiment)\n",
        "    \n",
        "    outstr=[\"R\",\"c\",\"c-plus-plus\",\"c-sharp\",\"dart\",\"f-sharp\",\"go\",\"java\",\"javascript\",\"julia\",\"php\",\"python\",\"ruby\",\"scala\",\"swift\"]\n",
        "    yout=[outstr[i] for i in yout_index]   \n",
        "\n",
        "    \n",
        "    return(yout)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnV8IalHsayM"
      },
      "outputs": [],
      "source": [
        "y_pred_list=[list(y_pred_i) for y_pred_i in y_pred] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoTV8E19suWW"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[6.670681e-08,\n",
              " 2.249829e-07,\n",
              " 7.969105e-09,\n",
              " 5.587469e-10,\n",
              " 3.6485848e-09,\n",
              " 3.1074666e-08,\n",
              " 2.487764e-08,\n",
              " 8.421797e-11,\n",
              " 4.4194178e-07,\n",
              " 4.330109e-05,\n",
              " 3.0215615e-06,\n",
              " 0.9999504,\n",
              " 2.2594738e-06,\n",
              " 2.8806116e-07,\n",
              " 5.812443e-10]"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_list[27]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itw7lX_hqO5m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[8, 11, 4, 12, 2, 7, 11, 11, 7, 7, 7, 2, 1, 3, 2, 2, 2, 2, 2, 11, 11, 2, 11, 11, 2, 2, 7, 11, 2, 2, 11, 11, 11, 11, 2, 3, 2, 2, 11, 2, 7, 2, 2, 11, 2, 2, 1, 11, 2, 5, 11, 11, 2, 1, 7, 7, 2, 2, 7, 2, 2, 2, 11, 11, 8, 2, 2, 2, 2, 6, 11, 2, 8, 1, 11, 1, 1, 11, 2, 11, 7, 2, 2, 11, 2, 2, 2, 11, 2, 2, 2, 2, 12, 1, 11, 11, 11, 2, 3, 11, 11, 11, 7, 2, 1, 3, 10, 1, 11, 7, 11, 1, 8, 12, 11, 11, 3, 8, 3, 11, 11, 5, 0, 4, 2, 11, 11, 3, 1, 2, 2, 2, 11, 1, 11, 3, 3, 3, 2, 11, 7, 11, 11, 3, 7, 1, 2, 4, 8, 2, 2, 2, 11, 2, 2, 2, 2, 2, 6, 11, 2, 1, 11, 6, 2, 11, 9, 2, 2, 2, 2, 2, 3, 2, 8, 6, 11, 2, 6, 2, 7, 2, 2, 4, 11, 2, 3, 11, 2, 2, 7, 1, 7, 2, 8, 1, 11, 11, 2, 7, 11, 3, 2, 11, 9, 7, 6, 8, 8, 7, 2, 1, 8, 2, 1, 7, 2, 11, 1, 1, 11, 2, 1, 11, 8, 2, 3, 2, 3, 1, 7, 8, 8, 11, 2, 11, 11, 2, 4, 1, 12, 1, 11, 2, 7, 6, 1, 11, 3, 2, 8, 2, 1, 1, 12, 11, 1, 3, 7, 2, 11, 7, 7, 2, 3, 1, 3, 8, 2, 2, 1, 7, 1, 8, 11, 2, 1, 2, 6, 7, 1, 11, 2, 2, 2, 11, 1, 4, 3, 2, 2, 7, 11, 2, 2, 3, 8, 11, 7, 2, 11, 7, 7, 11, 2, 6, 7, 2, 2, 2, 3, 7, 3, 11, 2, 2, 11, 3, 2, 1, 11, 2, 2, 2, 6, 11, 1, 8, 2, 11, 3, 2, 11, 2, 2, 2, 7, 2, 2, 11, 11, 3, 2, 2, 2, 7, 11, 6, 2, 2, 11, 7, 11, 11, 1, 7, 1, 3, 2, 11, 3, 7, 7, 11, 11, 7, 6, 2, 9, 11, 1, 11, 11, 1, 8, 1, 0, 2, 7, 2, 2, 2, 9, 3, 11, 11, 4, 6, 2, 7, 2, 3, 2, 2, 11, 2, 6, 2, 2, 2, 3, 6, 2, 2, 3, 12, 9, 4, 7, 4, 1, 7, 1, 2, 2, 8, 11, 11, 2, 1, 6, 1, 2, 11, 1, 9, 7, 2, 11, 11, 1, 11, 8, 11, 2, 7, 8, 7, 7, 2, 7, 9, 11, 2, 1, 7, 2, 2, 8, 7, 11, 2, 1, 11, 9, 12, 2, 2, 3, 8, 8, 11, 11, 11, 3, 8, 11, 2, 3, 3, 2, 2, 8, 6, 2, 11, 11, 12, 7, 2, 6, 11, 7, 2, 7, 14, 11, 2, 11, 2, 9, 5, 1, 8, 11, 11, 7, 3, 6, 6, 3, 2, 4, 2, 4, 3, 9, 2, 7, 8, 2, 11, 4, 11, 11, 9, 3, 11, 2, 11, 7, 2, 9, 1, 3, 7, 6, 2, 1, 11, 2, 11, 11, 11, 12, 2, 7, 1, 7, 7, 2, 1, 11, 11, 11, 11, 2, 1, 11, 7, 3, 1, 2, 2, 3, 2, 7, 8, 3, 3, 8, 8, 6, 1, 1, 11, 2, 2, 11, 2, 2, 9, 1, 2, 2, 11, 11, 1, 3, 1, 7, 11, 11, 11, 11, 8, 11, 2, 2, 4, 2, 3, 2, 1, 2, 3, 7, 7, 4, 8, 11, 2, 7, 11, 6, 1, 3, 2, 2, 7, 2, 2, 2, 2, 2, 7, 8, 2, 2, 12, 11, 2, 1, 3, 2, 2, 3, 1, 11, 1, 11, 7, 8, 6, 1, 2, 11, 11, 4, 11, 1, 2, 1, 7, 6, 2, 5, 11, 2, 6, 11, 3, 7, 11, 11, 11, 11, 1, 7, 2, 2, 3, 7, 2, 12, 2, 11, 7, 2, 6, 2, 8, 8, 8, 11, 2, 11, 1, 7, 2, 12, 3, 1, 3, 11, 7, 2, 1, 3, 7, 3, 7, 11, 2, 3, 4, 11, 2, 1, 2, 11, 8, 2, 2, 2, 11, 2, 1, 3, 7, 10, 6, 1, 9, 7, 12, 11, 3, 11, 2, 8, 1, 3, 1, 7, 6, 3, 3, 3, 2, 3, 4, 3, 3, 9, 2, 12, 1, 11, 12, 11, 1, 1, 2, 2, 3, 2, 4, 11, 2, 2, 7, 2, 11, 11, 12, 11, 9, 2, 2, 6, 2, 3, 1, 11, 11, 11, 7, 4, 2, 8, 8, 1, 8, 12, 13, 3, 11, 1, 2, 8, 7, 2, 7, 2, 8, 8, 8, 2, 11, 7, 2, 3, 8, 2, 3, 7, 2, 2, 2, 2, 1, 7, 2, 3, 11, 11, 3, 6, 3, 2, 2, 8, 2, 7, 2, 7, 7, 2, 3, 7, 3, 6, 2, 7, 2, 11, 12, 11, 1, 6, 1, 7, 2, 7, 8, 11, 2, 3, 11, 1, 7, 11, 11, 1, 1, 11, 2, 11, 1, 2, 2, 3, 2, 7, 6, 8, 11, 3, 7, 8, 7, 3, 11, 13, 9, 7, 2, 3, 7, 2, 5, 12, 3, 2, 11, 2, 11, 2, 2, 7, 2, 11, 8, 9, 11, 2, 7, 2, 2, 8, 11, 11, 2, 2, 11, 7, 11, 8, 11, 8, 11, 3, 2, 11, 2, 3, 1, 9, 1, 11, 12, 2, 11, 11, 11, 1, 11, 2, 2, 11, 11, 2, 11, 11, 11, 11, 1, 11, 11, 8, 2, 2, 1, 0, 7, 1, 2, 1, 2, 11, 11, 8, 3, 7, 11, 7, 2, 2, 2, 2, 2, 1, 11, 2, 7, 7, 11, 2, 2, 11, 9, 1, 9, 0, 7, 7, 8, 3, 11, 11, 9, 8, 8, 2, 11, 6, 3, 8, 2, 7, 7, 11, 11, 3, 11, 7, 2, 2, 2, 11, 8, 1, 3, 8, 2, 7, 1, 3, 2, 11, 11, 6, 7, 11, 8, 2, 11, 2, 6, 12, 3, 3, 9, 11, 7, 2, 12, 1, 2, 2, 2, 3, 7, 2, 3, 11, 8, 2, 2, 2, 2, 2, 11, 11, 1, 1, 2, 3, 4, 2, 2, 11, 3, 1, 3, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 12, 1, 8, 2, 7, 3, 1, 11, 7, 7, 2, 8, 4, 11, 2, 1, 0, 0, 7, 7, 3, 2, 11, 3, 1, 12, 6, 8, 11, 6, 1, 6, 1, 7, 11, 11, 6, 3, 11, 2, 1, 8, 11, 1, 11, 3, 8, 2, 3, 6, 1, 2, 3, 11, 1, 11, 8, 1, 2, 2, 2, 7, 11, 4, 6, 11, 8, 12, 1, 11, 2, 2, 3, 2, 11, 7, 11, 2, 11, 1, 11, 2, 8, 2, 14, 11, 4, 12, 7, 11, 8, 10, 6, 2, 3, 3, 2, 10, 2, 3, 1, 14, 2, 2, 7, 8, 11, 2, 7, 3, 1, 11, 11, 11, 3, 11, 3, 2, 7, 2, 3, 2, 11, 11, 12, 11, 1, 7, 2, 11, 3, 2, 1, 8, 11, 7, 11, 6, 2, 2, 11, 12, 3, 3, 2, 6, 2, 2, 2, 11, 11, 2, 1, 2, 11, 7, 2, 1, 3, 3, 11, 2, 2, 7, 1, 11, 1, 6, 1, 7, 1, 2, 8, 7, 11, 11, 7, 6, 4, 11, 11, 2, 2, 2, 6, 9, 1, 3, 2, 11, 2, 2, 6, 6, 12, 1, 7, 2, 6, 3, 11, 11, 9, 3, 12, 3, 8, 6, 1, 2, 1, 11, 11, 7, 11, 11, 11, 8, 8, 3, 7, 9, 2, 2, 11, 1, 8, 2, 7, 4, 1, 1, 7, 3, 12, 6, 3, 7, 3, 8, 3, 5, 11, 7, 2, 1, 3, 6, 2, 11, 7, 2, 11, 6, 11, 2, 2, 11, 6, 1, 11, 8, 2, 11, 3, 1, 2, 3, 3, 2, 1, 2, 7, 8, 11, 1, 2, 11, 8, 2, 2, 11, 8, 8, 2, 3, 11, 1, 3, 3, 2, 11, 11, 1, 2, 8, 3, 11, 11, 2, 6, 6, 12, 3, 11, 1, 11, 11, 12, 2, 11, 1, 3, 8, 2, 9, 4, 7, 11, 2, 1, 2, 3, 1, 11, 2, 11, 2, 3, 11, 7, 2, 11, 11, 3, 6, 3, 2, 11, 6, 2, 2, 2, 11, 1, 4, 6, 4, 11, 1, 2, 7, 11, 11, 3, 2, 1, 2, 3, 11, 11, 11, 11, 7, 11, 3, 2, 1, 6, 1, 7, 2, 11, 2, 1, 6, 3, 3, 11, 11, 2, 6, 2, 3, 7, 2, 11, 4, 11, 11, 1, 9, 2, 3, 2, 13, 2, 11, 7, 1, 1, 2, 1, 7, 11, 2, 2, 3, 2, 1, 2, 11, 7, 3, 2, 3, 1, 8, 11, 1, 1, 3, 7, 7, 2, 11, 2, 7, 11, 2, 9, 11, 11, 2, 3, 11, 4, 1, 7, 1, 2, 11, 8, 2, 6, 8, 1, 7, 2, 1, 4, 6, 2, 2, 6, 2, 1, 7, 1, 1, 1, 11, 1, 1, 2, 9, 11, 2, 2, 2, 8, 7, 11, 2, 7, 3, 11, 8, 12, 11, 11, 9, 2, 8, 6, 2, 7, 11, 11, 7, 2, 7, 11, 11, 1, 2, 11, 7, 2, 3, 3, 11, 7, 11, 2, 11, 8, 11, 8, 3, 11, 2, 2, 7, 3, 2, 7, 1, 11, 1, 2, 1, 7, 11, 1, 7, 11, 2, 11, 6, 8, 11, 4, 8, 3, 2, 11, 3, 2, 4, 4, 12, 6, 11, 8, 8, 3, 7, 1, 2, 2, 3, 5, 2, 11, 8, 2, 2, 2, 7, 11, 2, 3, 11, 3, 3, 11, 11, 3, 11, 11, 8, 8, 2, 2, 6, 2, 2, 7, 11, 1, 7, 11, 1, 12, 3, 3, 11, 9, 11, 11, 7, 7, 11, 3, 2, 3, 11, 4, 2, 2, 8, 2, 2, 11, 2, 3, 7, 1, 11, 2, 12, 11, 11, 2, 8, 11, 7, 6, 2, 1, 2, 11, 3, 7, 7, 12, 2, 2, 2, 2, 2, 2, 2, 1, 11, 2, 2, 7, 2, 1, 7, 11, 11, 11, 7, 4, 3, 8, 8, 2, 2, 11, 8, 11, 11, 2, 3, 3, 7, 7, 11, 2, 8, 6, 7, 3, 11, 2, 3, 7, 2, 2, 2, 2, 11, 2, 11, 2, 2, 2, 2, 6, 2, 2, 6, 2, 2, 2, 12, 4, 11, 3, 10, 11, 11, 6, 7, 11, 12, 2, 7, 3, 11, 11, 7, 1, 2, 2, 7, 1, 7, 11, 2, 2, 2, 3, 1, 11, 10, 1, 2, 11, 3, 2, 11, 9, 6, 3, 2, 11, 11, 2, 7, 2, 1, 8, 8, 5, 9, 2, 9, 7, 6, 2, 2, 1, 11, 2, 1, 7, 8, 3, 1, 1, 8, 7, 2, 1, 8, 1, 8, 2, 11, 3, 7, 3, 11, 7, 7, 11, 2, 1, 2, 2, 11, 3, 11, 11, 6, 11, 11, 11, 11, 4, 11, 1, 11, 7, 8, 2, 3, 3, 11, 11, 7, 1, 3, 2, 1, 2, 2, 4, 11, 11, 2, 6, 2, 1, 2, 9, 7, 11, 3, 6, 1, 11, 3, 3, 11, 3, 2, 1, 3, 2, 11, 1, 3, 2, 2, 6, 2, 11, 6, 3, 11, 11, 2, 7, 1, 11, 1, 3, 2, 7, 12, 2, 2, 3, 1, 2, 9, 1, 7, 2, 2, 2, 1, 2, 2, 6, 2, 3, 11, 5, 2, 2, 2, 11, 11, 11, 11, 6, 1, 3, 7, 11, 11, 1, 2, 1, 11, 11, 3, 2, 11, 2, 11, 2, 8, 11, 2, 11, 11, 1, 2, 2, 3, 8, 2, 3, 8, 8, 2, 11, 2, 6, 3, 11, 2, 2, 11, 2, 2, 9, 11, 11, 2, 11, 2, 11, 2, 8, 11, 11, 8, 9, 2, 7, 2, 8, 11, 11, 2, 2, 2, 3, 2, 12, 6, 2, 6, 2, 13, 3, 7, 7, 7, 11, 2, 6, 2, 2, 12, 1, 2, 2, 2, 11, 11, 2, 11, 3, 8, 3, 2, 11, 1, 3, 6, 11, 3, 11, 2, 2, 3, 2, 7, 8, 2, 2, 11, 2, 7, 1, 6, 2, 7, 2, 3, 6, 2, 12, 1, 2, 2, 11, 11, 2, 1, 1, 2, 2, 3, 11, 6, 2, 11, 3, 11, 11, 9, 11, 4, 4, 11, 1, 6, 7, 11, 1, 3, 1, 7, 3, 2, 2, 8, 1, 6, 2, 8, 7, 11, 7, 3, 8, 1, 7, 6, 11, 3, 7, 3, 2, 11, 2, 2, 2, 3, 2, 11, 7, 11, 11, 12, 2, 1, 11, 2, 11, 11, 11, 6, 3, 11, 3, 2, 11, 6, 2, 11, 11, 8, 8, 7, 11, 7, 4, 3, 2, 11, 7, 7, 11, 3, 2, 11, 11, 2, 11, 11, 8, 2, 11, 4, 2, 2, 2, 12, 4, 2, 11, 8, 2, 12, 3, 3, 2, 11, 1, 12, 1, 2, 1, 1, 2, 1, 2, 2, 3, 6, 2, 8, 7, 1, 7, 11, 2, 2, 8, 2, 1, 2, 1, 3, 2, 7, 14, 2, 7, 2, 2, 7, 2, 3, 2, 2, 3, 11, 8, 1, 11, 7, 2, 2, 4, 2, 7, 1, 3, 12, 1, 4, 1, 2, 9, 2, 2, 1, 11, 1, 7, 1, 11, 8, 11, 11, 11, 1, 8, 11, 4, 2, 11, 11, 11, 7, 6, 3, 2, 11, 3, 11, 2, 3, 8, 1, 6, 11, 11, 2, 7, 2, 2, 2, 8, 12, 3, 8, 3, 1, 1, 11, 2, 6, 11, 2, 2, 11, 6, 6, 1, 11, 3, 11, 2, 8, 2, 1, 12, 13, 2, 7, 2, 2, 11, 2, 11, 6, 11, 3, 11, 11, 8, 3, 7, 11, 7, 7, 2, 11, 1, 1, 4, 10, 2, 3, 11, 6, 14, 11, 2, 1, 2, 9, 2, 2, 2, 2, 3, 11, 7, 7, 6, 3, 11, 3, 2, 2, 8, 7, 9, 11, 2, 7, 1, 2, 7, 3, 2, 1, 3, 6, 2, 4, 2, 11, 2, 6, 1, 2, 2, 2, 8, 11, 2, 11, 8, 3, 6, 11, 3, 7, 8, 6, 9, 2, 7, 2, 1, 2, 7, 4, 11, 9, 3, 2, 2, 2, 2, 11, 3, 8, 11, 4, 7, 3, 2, 7, 3, 11, 6, 4, 2, 0, 7, 11, 12, 6, 3, 1, 7, 4, 2, 7, 3, 8, 7, 11, 11, 11, 7, 11, 1, 2, 6, 3, 8, 2, 11, 7, 3, 7, 7, 7, 11, 7, 2, 11, 2, 11, 11, 6, 3, 7, 7, 11, 12, 9, 7, 2, 2, 3, 7, 11, 11, 11, 8, 2, 8, 2, 7, 2, 11, 11, 1, 8, 11, 11, 7, 3, 3, 4, 11, 2, 11, 2, 3, 7, 11, 9, 11, 7, 7, 11, 2, 2, 9, 1, 6, 8, 6, 2, 11, 1, 8, 11, 3, 2, 2, 2, 3, 8, 2, 9, 2, 3, 1, 2, 2, 11, 9, 2, 11, 6, 2, 11, 7, 2, 7, 4, 2, 1, 1, 2, 1, 7, 1, 11, 2, 3, 7, 11, 2, 2, 11, 8, 2, 2, 11, 2, 6, 11, 2, 2, 14, 2, 7, 3, 7, 2, 8, 2, 2, 3, 7, 7, 6, 4, 1, 11, 11, 12, 1, 12, 3, 1, 1, 11, 6, 11, 9, 11, 8, 11, 1, 8, 2, 3, 11, 9, 1, 6, 6, 2, 6, 7, 2, 11, 7, 1, 9, 11, 8, 2, 2, 2, 2, 2, 2, 11, 2, 2, 2, 11, 8, 2, 2, 11, 3, 9, 11, 1, 1, 1, 2, 8, 3, 2, 11, 2, 2, 11, 2, 2, 11, 11, 3, 7, 8, 10, 11, 11, 2, 3, 4, 1, 1, 3, 7, 7, 1, 11, 11, 11, 2, 2, 2, 12, 3, 2, 2, 4, 1, 7, 7, 3, 2, 7, 3, 2, 12, 1, 1, 1, 11, 11, 7, 5, 2, 11, 1, 7, 7, 7, 11, 1, 8, 2, 2, 11, 11, 1, 7, 2, 11, 2, 3, 2, 12, 4, 1, 7, 9, 2, 3, 4, 11, 2, 2, 11, 11, 11, 3, 9, 11, 11, 2, 2, 11, 2, 2, 11, 2, 11, 6, 11, 2, 11, 2, 2, 2, 2, 1, 3, 2, 3, 1, 2, 8, 6, 3, 4, 2, 6, 7, 2, 8, 2, 7, 1, 7, 2, 7, 6, 7, 11, 1, 2, 3, 3, 7, 6, 2, 6, 11, 11, 3, 2, 11, 8, 7, 2, 1, 7, 11, 3, 11, 2, 1, 11, 11, 11, 8, 8, 11, 3, 2, 11, 3, 3, 2, 11, 2, 11, 2, 11, 8, 1, 3, 3, 2, 11, 8, 7, 3, 3, 11, 3, 3, 2, 11, 1, 11, 2, 4, 2, 2, 2, 3, 11, 7, 7, 11, 6, 11, 8, 11, 6, 1, 2, 11, 4, 2, 11, 3, 7, 8, 7, 2, 2, 2, 8, 8, 6, 2, 7, 9, 8, 6, 2, 6, 11, 11, 11, 2, 3, 3, 2, 1, 2, 4, 2, 3, 11, 2, 12, 2, 7, 1, 2, 2, 3, 11, 12, 3, 3, 7, 11, 9, 9, 3, 1, 6, 11, 2, 9, 11, 7, 1, 7, 2, 3, 1, 2, 2, 12, 6, 9, 4, 3, 1, 2, 2, 2, 11, 2, 11, 6, 2, 11, 11, 11, 4, 6, 2, 2, 2, 2, 2, 8, 9, 2, 2, 8, 11, 11, 2, 1, 3, 7, 11, 2, 8, 5, 7, 8, 11, 3, 1, 11, 8, 7, 8, 3, 1, 1, 11, 12, 11, 2, 2, 11, 3, 2, 1, 11, 1, 3, 1, 11, 2, 1, 11, 8, 1, 1, 2, 2, 11, 6, 11, 11, 11, 1, 11, 3, 7, 8, 11, 6, 2, 1, 10, 7, 2, 2, 7, 7, 11, 2, 2, 3, 1, 11, 11, 2, 1, 3, 1, 2, 1, 2, 2, 7, 7, 9, 2, 1, 3, 1, 11, 1, 3, 1, 1, 7, 3, 7, 2, 2, 11, 11, 11, 1, 8, 11, 12, 11, 3, 7, 11, 8, 11, 2, 2, 11, 6, 7, 3, 11, 11, 11, 2, 7, 11, 7, 10, 6, 3, 3, 2, 11, 2, 11, 6, 2, 11, 11, 1, 4, 4, 7, 0, 1, 11, 2, 2, 11, 1, 7, 8, 2, 6, 11, 2, 11, 2, 3, 1, 3, 7, 6, 11, 6, 2, 3, 2, 7, 2, 11, 6, 8, 3, 1, 11, 8, 3, 2, 2, 7, 2, 1, 3, 2, 1, 2, 6, 7, 7, 6, 2, 2, 2, 11, 2, 3, 8, 2, 3, 7, 11, 9, 2, 11, 1, 3, 2, 7, 11, 2, 7, 8, 11, 4, 11, 8, 12, 2, 2, 1, 9, 11, 3, 3, 1, 7, 11, 1, 2, 3, 11, 1, 11, 6, 8, 9, 11, 11, 11, 3, 1, 2, 7, 7, 11, 2, 7, 2, 11, 2, 2, 3, 2, 2, 2, 2, 2, 8, 1, 2, 2, 2, 11, 1, 11, 6, 6, 2, 6, 2, 1, 11, 3, 3, 8, 11, 11, 5, 2, 11, 7, 8, 11, 11, 2, 2, 2, 2, 2, 9, 11, 11, 4, 7, 12, 2, 7, 1, 3, 11, 7, 11, 11, 1, 2, 2, 1, 1, 7, 9, 8, 11, 11, 7, 1, 7, 2, 1, 8, 6, 8, 1, 3, 3, 11, 7, 2, 8, 6, 4, 7, 6, 2, 11, 2, 11, 2, 6, 3, 11, 2, 2, 11, 2, 1, 6, 11, 7, 2, 2, 11, 6, 2, 11, 11, 7, 7, 8, 1, 2, 2, 1, 7, 2, 2, 12, 11, 8, 3, 11, 2, 8, 11, 5, 11, 4, 1, 11, 6, 2, 2, 3, 7, 11, 2, 7, 8, 7, 11, 1, 11, 3, 3, 7, 2, 10, 2, 2, 11, 2, 3, 11, 1, 7, 3, 2, 7, 11, 2, 11, 7, 2, 3, 1, 3, 9, 7, 11, 2, 4, 11, 11, 8, 8, 11, 11, 3, 11, 12, 2, 1, 2, 11, 2, 12, 1, 2, 11, 11, 2, 11, 8, 11, 11, 11, 1, 5, 10, 6, 11, 6, 11, 3, 1, 2, 3, 11, 1, 2, 2, 12, 2, 1, 8, 7, 2, 2, 1, 8, 2, 3, 11, 2, 2, 2, 8, 2, 6, 11, 6, 12, 11, 2, 7, 2, 3, 3, 2, 3, 7, 7, 3, 8, 2, 2, 3, 1, 6, 2, 2, 11, 6, 7, 6, 2, 6, 1, 6, 2, 2, 4, 2, 8, 11, 1, 2, 2, 11, 11, 2, 2, 1, 1, 11, 11, 2, 1, 6, 12, 11, 2, 2, 2, 3, 7, 1, 9, 2, 11, 2, 3, 2, 1, 3, 2, 3, 8, 12, 1, 11, 11, 8, 2, 3, 9, 11, 2, 2, 2, 7, 7, 8, 8, 2, 8, 2, 2, 11, 2, 11, 11, 2, 11, 1, 10, 11, 3, 11, 9, 8, 2, 3, 2, 11, 11, 3, 1, 2, 1, 11, 2, 0, 11, 2, 8, 3, 7, 7, 4, 11, 2, 8, 2, 9, 11, 11, 2, 4, 2, 11, 11, 11, 6, 11, 11, 2, 2, 2, 11, 11, 2, 11, 1, 2, 6, 2, 1, 3, 4, 2, 11, 11, 7, 11, 2, 2, 11, 3, 11, 1, 3, 3, 2, 2, 2, 1, 2, 2, 2, 3, 11, 8, 2, 3, 2, 11, 8, 7, 11, 11, 11, 7, 1, 2, 8, 2, 11, 7, 11, 2, 3, 8, 8, 11, 11, 11, 2, 2, 2, 2, 8, 11, 1, 11, 7, 2, 8, 2, 7, 6, 0, 11, 7, 3, 1, 13, 3, 3, 2, 6, 7, 2, 11, 7, 7, 3, 7, 3, 8, 6, 1, 2, 3, 1, 11, 3, 11, 3, 6, 6, 11, 8, 7, 11, 7, 1, 4, 11, 11, 2, 7, 2, 2, 2, 11, 7, 3, 2, 8, 6, 3, 7, 10, 11, 11, 11, 11, 11, 1, 1, 2, 7, 2, 8, 2, 1, 2, 2, 3, 11, 7, 11, 11, 11, 3, 2, 11, 11, 2, 1, 2, 11, 11, 8, 11, 1, 3, 2, 6, 11, 6, 1, 11, 11, 12, 2, 2, 3, 1, 6, 1, 11, 11, 2, 11, 11, 1, 11, 11, 8, 2, 1, 1, 2, 2, 11, 6, 7, 9, 11, 11, 1, 2, 2, 2, 3, 2, 3, 2, 3, 8, 2, 2, 3, 7, 11, 8, 2, 2, 7, 2, 12, 7, 2, 11, 7, 2, 11, 11, 6, 3, 3, 8, 7, 2, 11, 2, 11, 11, 7, 11, 11, 3, 10, 11, 8, 8, 7, 7, 2, 2, 1, 2, 7, 3, 3, 3, 2, 3, 11, 2, 7, 11, 8, 11, 2, 2, 1, 1, 11, 2, 1, 2, 1, 4, 3, 11, 7, 1, 2, 3, 11, 2, 2, 2, 11, 6, 1, 2, 8, 9, 3, 3, 3, 8, 5, 3, 7, 2, 3, 3, 2, 1, 8, 3, 2, 14, 1, 2, 2, 2, 3, 8, 2, 12, 11, 7, 11, 11, 3, 3, 11, 7, 2, 2, 2, 2, 2, 6, 3, 7, 2, 11, 11, 2, 6, 2, 7, 3, 3, 14, 6, 0, 4, 7, 11, 6, 2, 6, 11, 11, 3, 6, 11, 1, 10, 11, 2, 6, 12, 3, 2, 11, 7, 2, 11, 1, 2, 11, 11, 7, 8, 11, 11, 3, 2, 4, 2, 11, 2, 11, 1, 11, 3, 2, 4, 7, 11, 12, 11, 11, 11, 11, 7, 4, 2, 2, 2, 11, 11, 7, 11, 8, 11, 8, 1, 8, 7, 3, 7, 11, 1, 2, 1, 3, 2, 2, 6, 11, 2, 2, 2, 2, 2, 7, 3, 3, 6, 2, 11, 11, 11, 2, 2, 3, 2, 11, 1, 2, 1, 4, 2, 11, 9, 3, 2, 2, 11, 11, 12, 11, 1, 3, 2, 3, 2, 8, 7, 12, 2, 11, 2, 6, 2, 12, 2, 6, 1, 11, 3, 2, 2, 8, 3, 3, 1, 4, 11, 2, 11, 11, 6, 11, 1, 11, 1, 2, 11, 11, 2, 3, 14, 3, 7, 1, 7, 3, 6, 11, 6, 11, 3, 3, 2, 11, 3, 2, 9, 11, 11, 2, 2, 11, 11, 2, 2, 7, 2, 7, 1, 11, 11, 6, 2, 11, 6, 2, 11, 6, 4, 4, 2, 11, 3, 2, 11, 11, 9, 11, 3, 8, 8, 2, 6, 2, 7, 11, 7, 5, 7, 1, 2, 11, 1, 10, 11, 6, 11, 8, 2, 11, 3, 7, 2, 9, 8, 2, 6, 3, 2, 11, 7, 11, 2, 4, 7, 11, 2, 11, 4, 11, 2, 12, 6, 2, 7, 3, 11, 8, 2, 4, 2, 1, 2, 3, 11, 3, 2, 3, 1, 11, 11, 11, 11, 11, 2, 6, 11, 2, 2, 6, 11, 6, 1, 2, 11, 2, 2, 11, 1, 12, 1, 2, 2, 3, 6, 11, 7, 11, 3, 3, 7, 9, 12, 11, 11, 11, 2, 2, 7, 3, 2, 2, 2, 2, 7, 3, 2, 11, 9, 8, 2, 2, 1, 7, 2, 11, 11, 6, 9, 7, 7, 3, 2, 11, 11, 2, 12, 8, 3, 2, 8, 2, 2, 11, 11, 8, 7, 11, 11, 2, 9, 11, 7, 12, 8, 7, 2, 1, 11, 4, 11, 3, 2, 2, 1, 2, 2, 1, 11, 2, 3, 3, 3, 2, 6, 9, 3, 4, 11, 2, 3, 11, 3, 2, 6, 2, 2, 4, 6, 8, 2, 11, 2, 2, 3, 9, 2, 1, 11, 11, 6, 2, 3, 3, 12, 7, 2, 1, 2, 1, 2, 11, 1, 3, 3, 3, 11, 2, 6, 7, 6, 7, 2, 8, 11, 2, 2, 3, 12, 11, 3, 11, 7, 11, 7, 1, 11, 1, 3, 6, 2, 7, 3, 11, 2, 11, 8, 11, 11, 12, 7, 7, 2, 1, 11, 2, 2, 12, 2, 2, 2, 2, 11, 1, 11, 3, 2, 2, 7, 11, 2, 11, 11, 2, 11, 1, 3, 2, 3, 8, 1, 3, 7, 1, 1, 11, 2, 7, 10, 2, 9, 7, 11, 3, 11, 8, 2, 2, 11, 9, 2, 6, 1, 3, 2, 3, 11, 2, 1, 7, 11, 8, 2, 3, 4, 8, 11, 3, 11, 7, 2, 1, 11, 8, 2, 3, 1, 3, 6, 7, 3, 11, 2, 12, 7, 8, 11, 7, 11, 2, 1, 2, 3, 2, 11, 11, 11, 2, 2, 6, 2, 2, 9, 6, 2, 3, 3, 2, 6, 1, 8, 1, 2, 4, 2, 6, 2, 8, 11, 1, 13, 1, 11, 1, 11, 8, 2, 11, 1, 12, 11, 11, 2, 2, 11, 1, 11, 2, 2, 3, 11, 2, 11, 2, 3, 2, 9, 1, 14, 2, 3, 11, 11, 7, 3, 2, 3, 6, 11, 11, 1, 2, 9, 2, 11, 11, 4, 1, 11, 2, 4, 11, 11, 4, 11, 8, 1, 2, 11, 6, 8, 12, 2, 2, 8, 2, 2, 11, 3, 2, 4, 5, 3, 2, 7, 3, 3, 11, 4, 11, 11, 11, 8, 7, 2, 11, 7, 11, 2, 6, 2, 11, 7, 2, 6, 11, 3, 11, 2, 4, 7, 11, 11, 2, 2, 3, 9, 2, 2, 2, 1, 1, 2, 2, 3, 7, 4, 2, 2, 1, 9, 7, 2, 11, 6, 1, 1, 2, 3, 3, 11, 3, 1, 4, 11, 3, 11, 2, 6, 11, 1, 1, 2, 11, 4, 11, 6, 12, 11, 2, 2, 12, 2, 6, 1, 12, 7, 11, 6, 11, 1, 7, 3, 9, 2, 2, 2, 2, 11, 11, 2, 3, 1, 2, 2, 3, 6, 8, 2, 11, 3, 3, 7, 1, 7, 3, 2, 7, 3, 8, 8, 2, 11, 8, 11, 8, 2, 2, 11, 11, 2, 11, 8, 6, 2, 11, 8, 10, 3, 11, 7, 1, 1, 2, 3, 6, 7, 1, 2, 4, 11, 11, 8, 8, 7, 2, 8, 1, 8, 6, 7, 2, 4, 11, 2, 11, 2, 2, 2, 2, 2, 12, 2, 11, 4, 7, 7, 7, 1, 9, 2, 3, 2, 3, 8, 3, 7, 7, 2, 2, 2, 7, 2, 11, 1, 3, 1, 3, 2, 2, 8, 11, 9, 11, 7, 2, 4, 2, 11, 2, 2, 8, 11, 4, 2, 2, 11, 11, 11, 3, 8, 2, 2, 3, 3, 7, 1, 11, 11, 2, 2, 2, 3, 2, 7, 11, 2, 8, 3, 9, 2, 2, 11, 1, 2, 11, 1, 7, 3, 8, 1, 11, 2, 2, 3, 11, 11, 3, 11, 2, 12, 3, 7, 2, 1, 7, 11, 6, 11, 6, 3, 3, 8, 11, 3, 2, 7, 11, 11, 3, 9, 2, 2, 2, 2, 7, 4, 2, 2, 3, 1, 2, 1, 8, 2, 11, 9, 11, 11, 7, 11, 7, 11, 2, 2, 3, 2, 1, 11, 6, 2, 8, 3, 1, 7, 3, 2, 8, 11, 7, 11, 2, 1, 8, 11, 2, 2, 11, 8, 11, 2, 2, 3, 11, 3, 3, 3, 7, 7, 11, 8, 8, 11, 11, 11, 3, 4, 3, 2, 1, 3, 2, 2, 2, 6, 11, 6, 11, 1, 7, 2, 3, 4, 3, 2, 11, 2, 6, 8, 11, 2, 2, 3, 3, 3, 11, 12, 11, 11, 3, 11, 8, 2, 2, 1, 1, 2, 2, 11, 3, 2, 2, 11, 7, 12, 7, 1, 11, 2, 3, 11, 2, 12, 3, 2, 11, 4, 2, 2, 1, 8, 4, 12, 2, 3, 2, 3, 11, 11, 2, 6, 1, 11, 11, 7, 11, 7, 2, 9, 8, 11, 7, 2, 2, 3, 11, 2, 2, 14, 8, 2, 2, 11, 2, 6, 3, 1, 2, 11, 2, 11, 2, 1, 1, 1, 7, 4, 3, 8, 1, 3, 6, 7, 2, 8, 3, 7, 1, 7, 4, 2, 2, 3, 3, 2, 7, 11, 7, 1, 3, 7, 8, 1, 2, 6, 6, 7, 9, 11, 11, 2, 3, 6, 2, 1, 11, 1, 11, 7, 11, 2, 3, 3, 2, 2, 11, 1, 2, 2, 11, 9, 2, 3, 8, 2, 13, 2, 1, 7, 11, 11, 7, 3, 7, 12, 3, 8, 2, 11, 2, 7, 7, 3, 2, 4, 1, 11, 2, 8, 11, 2, 2, 2, 3, 11, 7, 3, 2, 2, 6, 7, 11, 6, 11, 2, 11, 11, 4, 11, 12, 2, 6, 6, 2, 7, 1, 2, 11, 11, 3, 2, 11, 2, 2, 2, 3, 1, 1, 6, 8, 8, 11, 2, 8, 1, 8, 7, 2, 1, 7, 11, 7, 11, 6, 8, 1, 2, 2, 2, 2, 2, 4, 11, 12, 7, 8, 3, 11, 3, 8, 7, 7, 3, 7, 2, 6, 1, 1, 8, 7, 2, 6, 11, 3, 2, 6, 11, 11, 2, 3, 11, 4, 1, 1, 7, 2, 2, 9, 11, 3, 11, 2, 2, 1, 2, 6, 2, 2, 3, 11, 8, 2, 2, 11, 8, 11, 3, 3, 1, 7, 7, 8, 12, 1, 2, 2, 1, 2, 2, 7, 2, 7, 8, 6, 9, 4, 8, 6, 7, 11, 11, 1, 2, 2, 7, 1, 8, 8, 4, 12, 7, 2, 2, 1, 2, 2, 11, 1, 3, 11, 1, 3, 2, 12, 7, 2, 2, 12, 2, 2, 8, 7, 6, 8, 9, 3, 2, 2, 11, 7, 3, 4, 7, 2, 3, 2, 3, 3, 2, 12, 7, 1, 2, 7, 12, 1, 2, 3, 2, 8, 2, 8, 11, 3, 2, 13, 1, 5, 11, 2, 11, 1, 2, 9, 2, 11, 2, 8, 7, 2, 2, 2, 2, 11, 2, 11, 2, 6, 8, 1, 3, 2, 2, 2, 8, 11, 3, 11, 3, 3, 9, 3, 7, 7, 7, 4, 1, 1, 7, 3, 2, 11, 4, 11, 2, 1, 2, 3, 11, 1, 1, 7, 8, 1, 2, 8, 11, 2, 6, 2, 7, 4, 2, 2, 12, 2, 2, 2, 2, 1, 2, 11, 2, 2, 3, 2, 2, 3, 1, 2, 1, 8, 11, 6, 9, 3, 2, 2, 1, 11, 2, 7, 7, 2, 7, 11, 2, 6, 3, 2, 1, 2, 2, 2, 11, 2, 2, 7, 2, 8, 2, 6, 2, 2, 2, 11, 3, 11, 11, 11, 4, 2, 11, 11, 2, 7, 1, 7, 2, 7, 2, 8, 1, 2, 2, 2, 11, 2, 3, 4, 11, 1, 11, 2, 8, 1, 12, 2, 3, 2, 11, 11, 11, 2, 1, 3, 7, 2, 6, 7, 3, 6, 2, 11, 2, 3, 1, 2, 1, 11, 11, 2, 8, 2, 2, 7, 11, 8, 8, 11, 11, 11, 7, 8, 11, 8, 2, 3, 2, 2, 2, 7, 11, 3, 3, 7, 12, 1, 6, 11, 2, 2, 8, 11, 1, 2, 9, 6, 4, 11, 6, 11, 3, 3, 8, 7, 1, 1, 7, 11, 2, 8, 3, 12, 2, 2, 4, 7, 8, 1, 2, 2, 11, 2, 2, 11, 8, 11, 3, 1, 7, 7, 11, 7, 6, 7, 2, 2, 2, 3, 3, 3, 2, 6, 3, 4, 11, 2, 12, 1, 2, 11, 2, 1, 11, 3, 11, 3, 2, 1, 6, 2, 2, 6, 7, 11, 4, 6, 7, 3, 11, 3, 2, 11, 11, 11, 1, 11, 11, 3, 7, 0, 11, 11, 2, 11, 2, 8, 2, 7, 7, 7, 1, 11, 2, 2, 4, 11, 11, 2, 11, 3, 2, 10, 1, 11, 11, 2, 2, 1, 2, 2, 9, 3, 6, 8, 2, 11, 8, 11, 1, 2, 7, 3, 4, 11, 11, 2, 2, 2, 11, 11, 2, 2, 1, 4, 2, 2, 7, 1, 7, 11, 11, 6, 3, 3, 11, 2, 2, 11, 2, 3, 6, 4, 12, 2, 2, 3, 2, 6, 1, 1, 3, 11, 11, 2, 1, 2, 2, 2, 2, 1, 3, 7, 3, 9, 11, 2, 7, 2, 2, 7, 1, 1, 7, 11, 3, 11, 3, 11, 8, 11, 3, 11, 2, 11, 8, 2, 6, 3, 12, 1, 2, 2, 2, 2, 11, 3, 7, 11, 2, 7, 6, 2, 11, 3, 2, 7, 11, 2, 3, 2, 11, 2, 11, 2, 9, 6, 11, 2, 3, 11, 11, 11, 7, 2, 2, 2, 11, 11, 9, 2, 4, 11, 2, 11, 11, 7, 11, 6, 1, 2, 8, 9, 2, 11, 2, 8, 2, 6, 11, 6, 2, 3, 11, 2, 7, 2, 1, 3, 1, 11, 2, 8, 7, 11, 2, 2, 7, 4, 2, 3, 8, 3, 11, 3, 11, 1, 9, 2, 8, 11, 6, 11, 2, 6, 2, 11, 11, 11, 2, 11, 1, 2, 7, 1, 2, 8, 2, 8, 11, 11, 8, 7, 8, 2, 11, 3, 1, 6, 12, 2, 11, 2, 7, 6, 8, 1, 2, 2, 11, 8, 11, 3, 7, 1, 2, 11, 2, 2, 3, 2, 11, 2, 1, 1, 11, 6, 7, 11, 3, 3, 2, 11, 2, 1, 6, 3, 11, 3, 11, 11, 2, 11, 2, 2, 14, 11, 2, 0, 11, 4, 8, 7, 8, 7, 1, 11, 3, 3, 11, 2, 3, 11, 8, 7, 8, 7, 1, 2, 4, 7, 9, 7, 7, 3, 2, 11, 11, 11, 7, 1, 6, 3, 7, 1, 7, 7, 1, 2, 7, 1, 8, 9, 3, 2, 1, 2, 2, 7, 1, 11, 3, 2, 3, 3, 11, 4, 8, 3, 2, 6, 11, 11, 6, 2, 1, 2, 7, 2, 7, 3, 2, 1, 2, 8, 3, 2, 1, 11, 2, 1, 6, 7, 7, 3, 2, 8, 11, 11, 10, 1, 2, 3, 11, 8, 4, 1, 6, 3, 11, 6, 1, 1, 1, 3, 3, 1, 11, 2, 2, 11, 11, 1, 11, 5, 12, 8, 1, 3, 9, 11, 3, 1, 11, 6, 7, 8, 2, 11, 3, 2, 2, 7, 2, 11, 12, 2, 2, 7, 7, 8, 2, 2, 2, 7, 14, 11, 2, 2, 5, 11, 4, 2, 2, 11, 2, 2, 1, 3, 8, 1, 11, 4, 2, 2, 11, 8, 2, 9, 7, 2, 9, 2, 4, 2, 11, 2, 2, 7, 2, 11, 11, 2, 8, 11, 3, 2, 7, 2, 2, 8, 2, 11, 3, 2, 11, 9, 2, 3, 1, 7, 2, 2, 1, 6, 9, 2, 9, 3, 3, 1, 1, 3, 11, 6, 1, 11, 11, 7, 2, 2, 2, 6, 2, 11, 6, 7, 2, 8, 2, 9, 1, 9, 6, 7, 2, 2, 1, 11, 11, 8, 11, 2, 2, 2, 2, 11, 1, 11, 10, 7, 7, 2, 3, 7, 2, 11, 7, 6, 1, 11, 2, 3, 12, 11, 8, 5, 11, 7, 2, 11, 2, 8, 6, 2, 11, 6, 7, 3, 8, 7, 11, 11, 2, 3, 2, 6, 4, 1, 1, 11, 2, 6, 2, 8, 8, 7, 11, 9, 1, 7, 8, 2, 1, 2, 11, 7, 1, 3, 4, 7, 2, 2, 11, 2, 1, 2, 2, 4, 3, 11, 1, 2, 11, 3, 1, 3, 7, 4, 9, 11, 8, 11, 11, 11, 7, 11, 11, 7, 11, 11, 2, 11, 2, 2, 7, 2, 7, 2, 6, 2, 2, 7, 11, 11, 1, 2, 2, 8, 2, 2, 7, 8, 9, 2, 2, 6, 7, 1, 2, 2, 11, 11, 2, 3, 2, 1, 7, 11, 6, 11, 3, 11, 11, 12, 3, 12, 1, 11, 1, 7, 2, 2, 11, 7, 11, 2, 3, 1, 1, 2, 3, 2, 1, 3, 11, 1, 1, 2, 7, 1, 2, 7, 11, 12, 11, 11, 3, 1, 11, 2, 11, 1, 1, 2, 1, 2, 7, 2, 2, 1, 8, 9, 2, 2, 12, 9, 11, 11, 7, 6, 2, 1, 7, 2, 11, 11, 1, 3, 8, 7, 11, 1, 7, 2, 7, 3, 6, 1, 3, 7, 1, 11, 8, 1, 2, 1, 11, 1, 11, 2, 1, 11, 8, 3, 2, 11, 2, 6, 9, 7, 6, 7, 1, 3, 2, 11, 4, 7, 3, 2, 11, 1, 11, 11, 11, 13, 3, 8, 8, 1, 1, 11, 11, 2, 2, 7, 1, 11, 2, 2, 1, 11, 2, 2, 11, 8, 3, 2, 7, 9, 7, 2, 8, 2, 12, 11, 7, 2, 2, 8, 9, 11, 11, 11, 3, 2, 2, 2, 11, 7, 11, 11, 8, 2, 2, 11, 11, 2, 11, 1, 2, 1, 1, 7, 3, 2, 6, 2, 7, 2, 2, 2, 2, 2, 2, 2, 8, 3, 7, 2, 11, 1, 12, 1, 3, 7, 11, 11, 1, 3, 11, 1, 1, 11, 4, 11, 8, 1, 1, 2, 11, 3, 6, 1, 2, 2, 2, 1, 2, 1, 2, 7, 1, 1, 2, 6, 0, 11, 11, 2, 1, 1, 2, 11, 11, 2, 2, 1, 4, 6, 7, 3, 11, 6, 11, 3, 3, 11, 1, 2, 3, 11, 7, 12, 11, 9, 2, 7, 2, 4, 11, 3, 7, 6, 6, 11, 8, 3, 11, 2, 11, 2, 3, 6, 2, 6, 1, 11, 1, 11, 2, 3, 1, 1, 2, 6, 6, 4, 11, 2, 2, 11, 2, 2, 1, 0, 11, 11, 7, 11, 2, 11, 8, 3, 2, 7, 1, 3, 3, 2, 5, 11, 1, 1, 2, 3, 2, 2, 11, 8, 6, 2, 2, 11, 2, 8, 7, 11, 2, 11, 11, 12, 11, 12, 2, 11, 2, 6, 2, 2, 1, 3, 2, 11, 2, 2, 11, 7, 1, 11, 2, 1, 8, 2, 2, 13, 2, 2, 7, 1, 11, 11, 3, 11, 2, 11, 1, 11, 12, 7, 2, 7, 2, 2, 2, 11, 9, 2, 2, 3, 1, 3, 7, 1, 6, 1, 2, 1, 2, 3, 11, 4, 12, 6, 3, 11, 7, 7, 3, 1, 8, 8, 2, 2, 6, 7, 12, 11, 7, 11, 11, 2, 2, 11, 3, 1, 11, 2, 6, 7, 2, 11, 8, 1, 7, 11, 2, 1, 1, 2, 1, 12, 2, 1, 1, 2, 2, 2, 4, 3, 2, 11, 9, 6, 11, 7, 6, 1, 11, 1, 1, 7, 1, 8, 7, 1, 6, 2, 4, 2, 2, 1, 11, 4, 3, 2, 2, 3, 11, 11, 7, 11, 12, 11, 8, 11, 8, 2, 3, 11, 2, 12, 6, 7, 2, 11, 11, 1, 1, 11, 1, 11, 2, 11, 11, 11, 9, 2, 11, 6, 2, 2, 1, 2, 2, 12, 2, 11, 3, 11, 8, 11, 1, 6, 2, 2, 3, 1, 1, 2, 3, 11, 2, 1, 2, 7, 3, 2, 2, 2, 2, 1, 6, 3, 2, 11, 3, 11, 7, 4, 2, 2, 11, 9, 7, 7, 1, 11, 2, 6, 7, 7, 2, 7, 3, 11, 2, 2, 3, 1, 7, 2, 1, 2, 7, 7, 1, 11, 2, 2, 11, 2, 8, 11, 11, 2, 11, 1, 11, 7, 2, 2, 8, 11, 7, 11, 9, 9, 11, 2, 7, 7, 3, 2, 11, 2, 11, 3, 10, 7, 11, 2, 11, 7, 6, 11, 2, 9, 3, 2, 11, 1, 2, 11, 11, 7, 7, 2, 11, 2, 1, 7, 2, 3, 2, 7, 6, 11, 2, 6, 11, 2, 1, 7, 2, 11, 11, 2, 11, 6, 11, 1, 11, 3, 1, 11, 7, 2, 7, 11, 2, 11, 6, 11, 2, 8, 12, 4, 8, 3, 11, 8, 2, 2, 11, 2, 2, 6, 11, 8, 1, 2, 2, 11, 11, 2, 11, 2, 8, 11, 11, 11, 2, 8, 8, 5, 7, 13, 11, 11, 7, 14, 11, 3, 2, 3, 3, 2, 3, 8, 2, 2, 7, 2, 6, 3, 1, 2, 1, 7, 2, 7, 11, 3, 2, 2, 6, 11, 2, 4, 12, 11, 8, 6, 2, 3, 2, 11, 11, 3, 3, 2, 2, 2, 2, 2, 2, 11, 2, 11, 3, 11, 6, 3, 11, 14, 2, 7, 11, 8, 2, 1, 8, 1, 2, 1, 11, 2, 2, 2, 2, 1, 3, 11, 8, 1, 2, 2, 2, 2, 4, 2, 2, 6, 8, 3, 9, 8, 7, 1, 2, 3, 3, 2, 1, 7, 2, 1, 11, 11, 3, 11, 11, 3, 3, 7, 11, 1, 8, 11, 4, 2, 3, 1, 14, 2, 2, 11, 3, 2, 2, 1, 8, 7, 11, 1, 1, 2, 3, 1, 3, 7, 8, 7, 1, 2, 1, 2, 1, 11, 4, 11, 11, 11, 12, 7, 11, 1, 11, 4, 7, 2, 11, 2, 3, 8, 10, 2, 3, 11, 6, 1, 2, 2, 6, 2, 2, 11, 9, 8, 2, 11, 11, 1, 2, 3, 8, 11, 2, 3, 11, 2, 2, 11, 6, 12, 2, 2, 7, 12, 11, 9, 8, 1, 11, 1, 11, 1, 8, 7, 3, 11, 7, 9, 11, 1, 2, 2, 3, 9, 2, 8, 3, 2, 1, 2, 11, 11, 2, 2, 7, 7, 7, 3, 2, 3, 1, 2, 11, 2, 7, 11, 2, 2, 1, 11, 3, 6, 1, 11, 9, 7, 11, 11, 2, 2, 11, 3, 11, 11, 2, 3, 11, 1, 1, 1, 7, 11, 11, 6, 11, 1, 6, 8, 7, 7, 2, 2, 2, 2, 1, 3, 2, 9, 11, 3, 2, 2, 12, 2, 2, 11, 2, 4, 2, 8, 2, 1, 2, 2, 1, 2, 1, 11, 1, 2, 2, 2, 1, 8, 2, 7, 3, 2, 1, 2, 11, 11, 11, 11, 11, 8, 2, 6, 11, 2, 2, 2, 11, 2, 3, 3, 1, 1, 11, 3, 1, 1, 1, 1, 7, 12, 11, 2, 2, 1, 2, 2, 2, 12, 7, 2, 3, 2, 1, 1, 2, 2, 11, 4, 2, 11, 3, 8, 12, 7, 11, 11, 11, 3, 11, 2, 11, 8, 2, 2, 11, 8, 7, 8, 1, 11, 3, 2, 2, 2, 1, 9, 11, 11, 7, 6, 2, 12, 3, 2, 11, 1, 11, 12, 2, 1, 11, 2, 7, 6, 2, 8, 2, 2, 2, 7, 3, 1, 3, 2, 3, 11, 11, 11, 6, 3, 2, 12, 1, 11, 1, 3, 11, 7, 2, 1, 11, 1, 2, 11, 6, 2, 1, 7, 1, 11, 2, 6, 4, 7, 11, 9, 7, 1, 2, 12, 11, 1, 2, 2, 7, 2, 11, 2, 11, 3, 2, 3, 11, 2, 5, 2, 2, 6, 6, 11, 5, 11, 3, 8, 2, 3, 5, 2, 8, 11, 11, 8, 2, 11, 11, 2, 2, 8, 6, 3, 3, 1, 2, 11, 11, 3, 11, 7, 2, 2, 2, 7, 2, 2, 3, 11, 11, 4, 1, 4, 11, 1, 11, 7, 2, 2, 2, 2, 7, 2, 3, 2, 8, 7, 2, 7, 2, 11, 8, 11, 3, 6, 2, 11, 2, 8, 0, 11, 2, 2, 7, 3, 10, 1, 2, 2, 2, 12, 11, 2, 2, 3, 7, 7, 2, 2, 7, 2, 2, 2, 7, 2, 11, 7, 2, 2, 2, 2, 7, 12, 1, 11, 11, 2, 11, 1, 11, 11, 9, 9, 7, 1, 11, 2, 7, 1, 7, 12, 2, 8, 2, 11, 3, 6, 11, 11, 11, 7, 2, 2, 7, 7, 3, 7, 11, 11, 2, 11, 2, 3, 11, 11, 2, 2, 2, 1, 4, 11, 6, 3, 1, 2, 2, 1, 3, 2, 3, 2, 3, 11, 2, 7, 6, 11, 9, 2, 12, 7, 8, 2, 1, 1, 2, 2, 4, 3, 4, 2, 2, 11, 2, 3, 7, 8, 6, 8, 2, 8, 2, 2, 1, 11, 7, 11, 2, 2, 1, 2, 11, 6, 2, 9, 11, 11, 9, 3, 7, 2, 2, 3, 8, 2, 11, 2, 2, 6, 7, 11, 11, 2, 1, 2, 7, 1, 7, 2, 2, 3, 8, 3, 11, 4, 2, 11, 2, 3, 1, 7, 1, 11, 11, 2, 7, 7, 1, 1, 11, 4, 2, 2, 11, 2, 2, 3, 3, 2, 11, 4, 2, 2, 7, 11, 2, 11, 2, 2, 7, 4, 2, 2, 6, 12, 3, 2, 11, 8, 2, 1, 2, 11, 2, 11, 1, 7, 2, 2, 2, 7, 2, 2, 8, 2, 2, 0, 8, 11, 3, 8, 3, 4, 11, 14, 1, 6, 1, 6, 7, 2, 2, 7, 8, 2, 11, 11, 1, 2, 1, 2, 3, 4, 11, 2, 2, 11, 11, 8, 8, 8, 1, 11, 2, 11, 2, 1, 11, 3, 3, 2, 2, 2, 2, 2, 11, 11, 7, 6, 2, 9, 6, 11, 11, 2, 1, 8, 2, 3, 11, 8, 2, 12, 6, 2, 8, 2, 2, 11, 1, 7, 6, 11, 6, 11, 11, 1, 6, 11, 2, 2, 2, 7, 1, 2, 3, 11, 9, 8, 3, 2, 2, 11, 11, 11, 1, 2, 1, 2, 3, 2, 11, 2, 7, 7, 12, 3, 1, 1, 3, 11, 2, 6, 8, 2, 2, 2, 3, 2, 11, 2, 11, 1, 2, 8, 3, 3, 2, 2, 2, 3, 2, 11, 7, 6, 3, 8, 2, 2, 2, 2, 7, 2, 11, 2, 11, 11, 2, 11, 3, 2, 4, 2, 7, 8, 2, 3, 2, 4, 11, 11, 3, 11, 11, 12, 11, 1, 1, 3, 11, 7, 11, 11, 7, 2, 11, 3, 3, 11, 2, 7, 3, 6, 2, 3, 2, 2, 11, 6, 2, 6, 2, 3, 1, 11, 2, 2, 2, 11, 8, 8, 2, 2, 7, 11, 2, 11, 2, 7, 2, 8, 11, 11, 11, 11, 7, 7, 11, 7, 1, 2, 11, 3, 11, 11, 1, 6, 2, 11, 11, 3, 11, 2, 11, 6, 1, 11, 3, 3, 12, 2, 3, 11, 2, 6, 3, 2, 11, 7, 2, 11, 2, 1, 1, 11, 9, 3, 3, 2, 3, 2, 3, 1, 1, 2, 6, 2, 8, 2, 1, 11, 12, 3, 11, 6, 6, 4, 11, 2, 2, 2, 2, 11, 9, 2, 2, 11, 3, 1, 3, 2, 2, 11, 11, 2, 6, 2, 6, 7, 11, 11, 11, 2, 11, 11, 7, 3, 2, 7, 3, 2, 8, 7, 7, 2, 2, 2, 7, 2, 11, 11, 11, 9, 11, 1, 2, 2, 3, 7, 1, 11, 4, 2, 7, 7, 1, 11, 11, 2, 8, 2, 11, 11, 3, 11, 11, 11, 6, 11, 3, 8, 2, 8, 11, 2, 2, 9, 1, 2, 7, 11, 11, 1, 2, 11, 11, 11, 11, 1, 11, 2, 7, 7, 2, 7, 12, 11, 11, 11, 2, 3, 2, 2, 1, 1, 11, 3, 3, 2, 8, 3, 3, 8, 11, 2, 12, 2, 3, 1, 4, 7, 11, 1, 2, 1, 1, 11, 9, 8, 7, 7, 1, 2, 7, 11, 2, 11, 9, 7, 7, 1, 3, 3, 2, 1, 7, 2, 6, 11, 11, 13, 7, 11, 7, 2, 11, 3, 1, 6, 4, 11, 9, 1, 11, 13, 2, 11, 3, 11, 2, 2, 1, 11, 8, 11, 2, 8, 2, 1, 3, 2, 1, 8, 7, 7, 2, 7, 3, 2, 12, 2, 2, 11, 8, 2, 7, 3, 3, 2, 2, 1, 11, 4, 2, 3, 3, 11, 11, 6, 8, 7, 2, 2, 3, 1, 11, 2, 7, 3, 2, 11, 2, 11, 8, 11, 2, 2, 7, 2, 12, 4, 11, 12, 4, 2, 1, 2, 11, 7, 2, 3, 3, 2, 1, 6, 2, 2, 3, 11, 7, 7, 11, 3, 11, 3, 2, 2, 2, 6, 1, 11, 2, 2, 1, 11, 2, 11, 1, 11, 3, 11, 7, 7, 1, 2, 11, 8, 2, 4, 7, 11, 2, 4, 6, 2, 2, 7, 11, 3, 2, 3, 14, 12, 11, 2, 11, 11, 11, 6, 11, 11, 12, 2, 7, 7, 3, 3, 2, 3, 11, 1, 2, 9, 2, 6, 1, 3, 9, 7, 2, 2, 2, 3, 11, 11, 2, 11, 8, 11, 7, 1, 2, 2, 8, 3, 11, 2, 7, 11, 3, 7, 7, 2, 2, 11, 7, 5, 2, 1, 11, 3, 1, 7, 2, 8, 12, 11, 11, 7, 11, 9, 1, 2, 11, 2, 3, 7, 2, 3, 8, 7, 11, 2, 2, 2, 7, 11, 3, 7, 3, 11, 7, 8, 1, 11, 3, 3, 6, 3, 2, 0, 1, 7, 8, 7, 1, 8, 2, 3, 8, 2, 3, 1, 2, 1, 2, 11, 3, 2, 1, 3, 11, 8, 2, 11, 2, 7, 2, 1, 12, 11, 8, 6, 11, 6, 11, 11, 3, 2, 7, 11, 11, 8, 1, 11, 11, 2, 6, 2, 1, 2, 7, 2, 2, 3, 2, 11, 2, 2, 3, 1, 1, 11, 8, 2, 2, 11, 2, 2, 1, 2, 11, 7, 2, 7, 11, 2, 9, 2, 3, 1, 7, 1, 4, 1, 1, 3, 12, 3, 3, 11, 6, 12, 11, 9, 11, 2, 11, 11, 3, 11, 1, 2, 11, 0, 6, 11, 2, 11, 11, 2, 11, 8, 8, 3, 1, 8, 6, 3, 2, 2, 2, 6, 2, 1, 1, 2, 2, 1, 2, 2, 3, 2, 2, 7, 6, 2, 11, 3, 11, 11, 11, 2, 12, 11, 11, 2, 2, 11, 2, 1, 3, 1, 1, 2, 6, 2, 1, 6, 2, 11, 2, 7, 3, 7, 1, 2, 11, 7, 2, 11, 2, 3, 9, 1, 11, 2, 7, 8, 6, 2, 1, 2, 3, 3, 8, 1, 3, 8, 11, 1, 7, 7, 11, 11, 2, 3, 9, 3, 7, 2, 2, 9, 2, 11, 2, 1, 4, 2, 2, 6, 2, 2, 11, 11, 2, 2, 2, 3, 11, 1, 9, 2, 11, 3, 11, 1, 3, 2, 2, 3, 11, 2, 11, 2, 7, 11, 2, 2, 7, 7, 11, 7, 3, 11, 2, 1, 2, 1, 11, 1, 2, 11, 7, 2, 2, 11, 12, 11, 3, 3, 1, 11, 3, 7, 0, 2, 12, 3, 3, 3, 7, 7, 3, 8, 5, 11, 11, 11, 3, 8, 3, 2, 2, 7, 7, 9, 1, 3, 2, 2, 2, 11, 7, 7, 6, 3, 3, 8, 2, 7, 12, 3, 1, 4, 12, 6, 2, 7, 2, 1, 2, 11, 11, 7, 4, 2, 2, 2, 7, 7, 11, 2, 11, 2, 11, 1, 2, 3, 2, 2, 1, 1, 2, 12, 1, 3, 1, 1, 2, 7, 9, 11, 4, 8, 2, 2, 7, 3, 2, 3, 11, 11, 2, 1, 1, 1, 11, 1, 7, 7, 2, 7, 1, 6, 9, 11, 2, 2, 9, 9, 2, 11, 2, 3, 1, 8, 2, 9, 11, 7, 8, 8, 10, 2, 1, 2, 2, 11, 2, 2, 11, 12, 3, 11, 12, 9, 11, 8, 8, 3, 7, 2, 11, 7, 2, 2, 1, 1, 2, 11, 7, 3, 11, 3, 2, 2, 1, 2, 8, 6, 11, 2, 7, 11, 1, 2, 2, 11, 1, 1, 7, 3, 8, 1, 11, 4, 11, 7, 11, 2, 11, 11, 2, 1, 2, 11, 11, 3, 3, 2, 11, 3, 7, 1, 8, 12, 7, 3, 7, 8, 9, 1, 11, 3, 8, 11, 3, 8, 2, 11, 2, 11, 11, 3, 6, 1, 3, 3, 11, 2, 8, 1, 2, 2, 1, 3, 1, 2, 3, 2, 7, 2, 2, 4, 6, 11, 3, 11, 1, 1, 2, 4, 2, 11, 3, 3, 11, 11, 2, 2, 6, 2, 6, 8, 4, 2, 9, 11, 3, 3, 11, 2, 3, 3, 11, 1, 8, 2, 11, 7, 2, 2, 11, 1, 2, 1, 2, 2, 2, 5, 7, 2, 7, 11, 7, 4, 7, 3, 1, 2, 2, 6, 2, 2, 7, 11, 2, 11, 7, 11, 2, 3, 8, 2, 2, 2, 11, 1, 6, 7, 6, 1, 4, 7, 3, 7, 6, 2, 11, 7, 2, 3, 11, 11, 11, 1, 11, 1, 1, 2, 1, 2, 11, 7, 3, 2, 3, 2, 1, 2, 11, 6, 7, 2, 2, 7, 12, 2, 2, 8, 3, 4, 1, 3, 11, 9, 11, 11, 8, 1, 8, 2, 6, 7, 11, 3, 2, 2, 2, 1, 3, 3, 2, 11, 2, 2, 7, 1, 3, 11, 1, 8, 11, 11, 2, 2, 11, 2, 1, 11, 8, 2, 11, 2, 2, 11, 11, 1, 2, 2, 11, 7, 8, 3, 3, 11, 1, 11, 8, 2, 2, 2, 1, 2, 3, 8, 1, 1, 11, 2, 2, 2, 3, 2, 2, 7, 2, 2, 2, 11, 1, 1, 2, 3, 8, 11, 7, 2, 2, 3, 1, 6, 6, 9, 12, 1, 3, 11, 2, 3, 9, 2, 2, 11, 2, 8, 3, 2, 3, 2, 2, 11, 2, 11, 2, 1, 2, 6, 2, 11, 7, 2, 7, 6, 8, 2, 1, 12, 3, 11, 7, 14, 11, 3, 11, 11, 2, 12, 11, 11, 3, 7, 11, 11, 7, 7, 11, 9, 3, 11, 2, 3, 6, 11, 1, 7, 11, 2, 12, 11, 2, 4, 1, 11, 4, 2, 9, 2, 1, 1, 1, 2, 1, 7, 7, 2, 1, 1, 7, 11, 7, 2, 9, 2, 2, 7, 3, 11, 2, 3, 1, 7, 3, 7, 2, 7, 2, 2, 3, 11, 2, 11, 2, 2, 7, 2, 11, 7, 3, 11, 1, 2, 11, 1, 8, 11, 4, 8, 8, 2, 9, 11, 8, 2, 1, 1, 2, 3, 11, 2, 2, 3, 7, 10, 11, 11, 7, 2, 6, 1, 2, 2, 7, 8, 7, 8, 3, 6, 1, 12, 11, 4, 2, 8, 3, 1, 2, 11, 3, 1, 3, 9, 1, 8, 2, 9, 11, 7, 9, 8, 3, 12, 6, 11, 2, 2, 7, 11, 11, 12, 1, 1, 2, 11, 1, 2, 6, 2, 2, 11, 6, 1, 2, 2, 11, 2, 3, 2, 2, 3, 11, 11, 11, 9, 7, 3, 2, 11, 6, 2, 11, 11, 6, 4, 11, 7, 3, 7, 1, 2, 11, 2, 7, 8, 2, 2, 2, 11, 2, 2, 2, 2, 11, 2, 11, 2, 11, 6, 4, 6, 11, 11, 2, 2, 11]\n"
          ]
        }
      ],
      "source": [
        "y_pred_str=ylabel_deconvert_5(y_pred_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOQFlEC2oj2i"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1.5111945e-03, 6.8015913e-03, 3.0867407e-01, 2.7096412e-01,\n",
              "       4.4110790e-02, 3.7323891e-03, 8.5450221e-05, 3.9035782e-02,\n",
              "       2.8379276e-01, 3.3816998e-03, 1.3311194e-02, 1.8291062e-02,\n",
              "       1.8986185e-04, 2.0442191e-03, 4.0739342e-03], dtype=float32)"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred[18]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSRQc0kWojzb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G88pQ7jYojvu"
      },
      "outputs": [],
      "source": [
        "df_csv=pd.DataFrame()\n",
        "df_csv[\"id\"]=test_df[\"id\"]\n",
        "df_csv[\"prediction\"]=y_pred_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NSaY0zkyu1t"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10684</td>\n",
              "      <td>javascript</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17536</td>\n",
              "      <td>python</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>26383</td>\n",
              "      <td>dart</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>29090</td>\n",
              "      <td>ruby</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10482</td>\n",
              "      <td>c-plus-plus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>11952</td>\n",
              "      <td>java</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>33227</td>\n",
              "      <td>python</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>87635</td>\n",
              "      <td>python</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>29183</td>\n",
              "      <td>java</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>93219</td>\n",
              "      <td>java</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11864</td>\n",
              "      <td>java</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>40466</td>\n",
              "      <td>c-plus-plus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>62931</td>\n",
              "      <td>c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>21621</td>\n",
              "      <td>c-sharp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>24775</td>\n",
              "      <td>c-plus-plus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>70170</td>\n",
              "      <td>c-plus-plus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>12357</td>\n",
              "      <td>c-plus-plus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>25732</td>\n",
              "      <td>c-plus-plus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>16981</td>\n",
              "      <td>c-plus-plus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>10841</td>\n",
              "      <td>python</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>51621</td>\n",
              "      <td>python</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>40668</td>\n",
              "      <td>c-plus-plus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>10870</td>\n",
              "      <td>python</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>29687</td>\n",
              "      <td>python</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>10008</td>\n",
              "      <td>c-plus-plus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>11708</td>\n",
              "      <td>c-plus-plus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>84005</td>\n",
              "      <td>java</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>26638</td>\n",
              "      <td>python</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>30137</td>\n",
              "      <td>c-plus-plus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>16869</td>\n",
              "      <td>c-plus-plus</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id   prediction\n",
              "0   10684   javascript\n",
              "1   17536       python\n",
              "2   26383         dart\n",
              "3   29090         ruby\n",
              "4   10482  c-plus-plus\n",
              "5   11952         java\n",
              "6   33227       python\n",
              "7   87635       python\n",
              "8   29183         java\n",
              "9   93219         java\n",
              "10  11864         java\n",
              "11  40466  c-plus-plus\n",
              "12  62931            c\n",
              "13  21621      c-sharp\n",
              "14  24775  c-plus-plus\n",
              "15  70170  c-plus-plus\n",
              "16  12357  c-plus-plus\n",
              "17  25732  c-plus-plus\n",
              "18  16981  c-plus-plus\n",
              "19  10841       python\n",
              "20  51621       python\n",
              "21  40668  c-plus-plus\n",
              "22  10870       python\n",
              "23  29687       python\n",
              "24  10008  c-plus-plus\n",
              "25  11708  c-plus-plus\n",
              "26  84005         java\n",
              "27  26638       python\n",
              "28  30137  c-plus-plus\n",
              "29  16869  c-plus-plus"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_csv.head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hw4CUPobbH7A"
      },
      "outputs": [],
      "source": [
        "from datetime  import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAbhqmcPdF6U"
      },
      "outputs": [],
      "source": [
        "a=datetime.now().strftime(\"%Y%m%d_%H%M%S\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiOwO9UTdeUt"
      },
      "outputs": [],
      "source": [
        "fname=\"submission_\"+a+\".csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ELciPC_OpWA"
      },
      "outputs": [],
      "source": [
        "df_csv.to_csv(fname,index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvmaQZGBYM_7"
      },
      "outputs": [],
      "source": [
        "if _OS_==\"linux\":\n",
        "    !head $fname"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrtPBTgcYwtg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0RCD1OKy7kJr",
        "YdZa4d2H7nO8",
        "hlKyrRqfG6GP"
      ],
      "history_visible": true,
      "name": "Programming_language_ID_convolution_20220101.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
